<!DOCTYPE html><html lang="en-US"><body> <script> var elements = document.querySelectorAll('p'); Array.prototype.forEach.call(elements, function(el, i){ if(el.innerHTML=='[expand]') { var parentcontent = el.parentNode.innerHTML.replace('<p>[expand]</p>','<div class="expand" style="display: none; height: 0; overflow: hidden;">').replace('<p>[/expand]</p>','</div>'); el.parentNode.innerHTML = parentcontent; } }); var elements = document.querySelectorAll('div.expand'); Array.prototype.forEach.call(elements, function(el, i){ el.previousElementSibling.innerHTML = el.previousElementSibling.innerHTML + '<span>..&nbsp; <a href="#" style="cursor: pointer;" onclick="this.parentNode.parentNode.nextElementSibling.style.display = \'block\'; this.parentNode.parentNode.nextElementSibling.style.height = \'auto\'; this.parentNode.style.display = \'none\';">read&nbsp;more&nbsp;&rarr;</a></span>'; }); </script> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-copy" viewBox="0 0 16 16"><title>Copy</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"><title>Copied</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"><path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg><div class="side-bar"><div class="site-header" role="banner"> <a href="/my-tech/" class="site-title lh-tight"> My SRE Stuff </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </a></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="/my-tech/" class="nav-list-link">My Page</a><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in AWS category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-tech/docs/AWS" class="nav-list-link">AWS</a><ul class="nav-list"><li class="nav-list-item "><a href="/my-tech/doc/AWS/creation-of-basic-infra/" class="nav-list-link">CloudFormation Stack Deployment Examples Part 1</a><li class="nav-list-item "><a href="/my-tech/doc/AWS/doc-2/" class="nav-list-link">Create an Infrastructure that runs redundant WordPress</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Ansible category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-tech/docs/Ansible" class="nav-list-link">Ansible</a><ul class="nav-list"><li class="nav-list-item "><a href="/my-tech/doc/Ansible/ansible-1/" class="nav-list-link">Create a host, ssh into the public EC2 instnace</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in CICD category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-tech/docs/CICD" class="nav-list-link">CICD</a><ul class="nav-list"></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Docker category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-tech/docs/Docker" class="nav-list-link">Docker</a><ul class="nav-list"><li class="nav-list-item "><a href="/my-tech/doc/Docker/docker-1/" class="nav-list-link">Docker First Setup From A Cloud Guru Part 1</a><li class="nav-list-item "><a href="/my-tech/doc/Docker/docker-2/" class="nav-list-link">Docker First Setup From A Cloud Guru Part 2</a></ul><li class="nav-list-item active"><button class="nav-list-expander btn-reset" aria-label="toggle items in Kubernetes category" aria-pressed="true"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-tech/docs/Kubernetes" class="nav-list-link active">Kubernetes</a><ul class="nav-list"><li class="nav-list-item "><a href="/my-tech/doc/Kubernetes/doc-1/" class="nav-list-link">Kubernetes 1.24 Installation</a><li class="nav-list-item "><a href="/my-tech/doc/Kubernetes/doc-2/" class="nav-list-link">CKA Preparation, 1.22</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Misc category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-tech/docs/Misc" class="nav-list-link">Misc</a><ul class="nav-list"><li class="nav-list-item "><a href="/my-tech/doc/Misc/template/" class="nav-list-link">tutorial about the running a sample docker image in numbered steps</a><li class="nav-list-item "><a href="/my-tech/template/" class="nav-list-link">Title</a><li class="nav-list-item "><a href="/my-tech/doc/Misc/tutorial-about-the-running-a-sample-docker-image-in-numbered-steps%20copy/" class="nav-list-link">tutorial about the running a sample docker image in numbered steps</a><li class="nav-list-item "><a href="/my-tech/doc/Misc/a-tutorial-about-creating-an-AWS-basic-infrastructure,-with-VPC,-publicc,-and-private-subnets,-IGW,-NAT,-security-groups,-EC2-and-RDS-that-runs-postgresql/" class="nav-list-link">a tutorial about creating an AWS basic infrastructure, with VPC, public, and private subnets, IGW, NAT, security groups, EC2 and RDS that runs postgresql</a></ul><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Terraform category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-tech/docs/Terraform" class="nav-list-link">Terraform</a><ul class="nav-list"><li class="nav-list-item "><a href="/my-tech/docs/Terraform/doc-1/" class="nav-list-link">Terraform Deployment of basic infrastructure on AWS</a></ul></ul></nav></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search" role="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search My SRE Stuff" aria-label="Search My SRE Stuff" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div></div><div id="main-content-wrap" class="main-content-wrap"><div id="main-content" class="main-content"><main><h1> Kubernetes</h1><h2></h2><h3> Date Posted: 2023 02 04</h3><h1 id="objective-1-cluster-architecture-installation--configuration"> <a href="#objective-1-cluster-architecture-installation--configuration" class="anchor-heading" aria-labelledby="objective-1-cluster-architecture-installation--configuration"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Objective 1: Cluster Architecture, Installation &amp; Configuration</h1><ul><li><a href="#objective-1-cluster-architecture-installation--configuration">Objective 1: Cluster Architecture, Installation \&amp; Configuration</a><ul><li><a href="#11-manage-role-based-access-control-rbac">1.1 Manage Role Based Access Control (RBAC)</a><ul><li><a href="#lab-environment">Lab Environment</a><li><a href="#lab-practice">Lab Practice</a></ul><li><a href="#12-use-kubeadm-to-install-a-basic-cluster">1.2 Use Kubeadm to Install a Basic Cluster</a><ul><li><a href="#kubeadm-tasks-for-all-nodes">Kubeadm Tasks for All Nodes</a><li><a href="#kubeadm-tasks-for-single-control-node">Kubeadm Tasks for Single Control Node</a><li><a href="#kubeadm-tasks-for-worker-nodes">Kubeadm Tasks for Worker Node(s)</a><li><a href="#kubeadm-troubleshooting">Kubeadm Troubleshooting</a><li><a href="#kubeadm-optional-tasks">Kubeadm Optional Tasks</a></ul><li><a href="#13-manage-a-highly-available-kubernetes-cluster">1.3 Manage A Highly-Available Kubernetes Cluster</a><ul><li><a href="#ha-deployment-types">HA Deployment Types</a><li><a href="#upgrading-from-single-control-plane-to-high-availability">Upgrading from Single Control-Plane to High Availability</a></ul><li><a href="#14-provision-underlying-infrastructure-to-deploy-a-kubernetes-cluster">1.4 Provision Underlying Infrastructure to Deploy a Kubernetes Cluster</a><li><a href="#15-perform-a-version-upgrade-on-a-kubernetes-cluster-using-kubeadm">1.5 Perform a Version Upgrade on a Kubernetes Cluster using Kubeadm</a><ul><li><a href="#first-control-plane-node">First Control Plane Node</a><li><a href="#additional-control-plane-nodes">Additional Control Plane Nodes</a><li><a href="#upgrade-control-plane-node-kubectl-and-kubelet-tools">Upgrade Control Plane Node Kubectl And Kubelet Tools</a><li><a href="#upgrade-worker-nodes">Upgrade Worker Nodes</a></ul><li><a href="#16-implement-etcd-backup-and-restore">1.6 Implement Etcd Backup And Restore</a><ul><li><a href="#snapshot-the-keyspace">Snapshot The Keyspace</a><li><a href="#restore-from-snapshot">Restore From Snapshot</a></ul></ul><li><a href="#objective-2-workloads--scheduling">Objective 2: Workloads \&amp; Scheduling</a><ul><li><a href="#21-understand-deployments-and-how-to-perform-rolling-update-and-rollbacks">2.1 Understand Deployments And How To Perform Rolling Update And Rollbacks</a><ul><li><a href="#create-deployment">Create Deployment</a><li><a href="#perform-rolling-update">Perform Rolling Update</a><li><a href="#perform-rollbacks">Perform Rollbacks</a></ul><li><a href="#22-use-configmaps-and-secrets-to-configure-applications">2.2 Use Configmaps And Secrets To Configure Applications</a><ul><li><a href="#configmaps">Configmaps</a><li><a href="#secrets">Secrets</a><li><a href="#other-concepts">Other Concepts</a></ul><li><a href="#23-know-how-to-scale-applications">2.3 Know How To Scale Applications</a><li><a href="#24-understand-the-primitives-used-to-create-robust-self-healing-application-deployments">2.4 Understand The Primitives Used To Create Robust, Self-Healing, Application Deployments</a><li><a href="#25-understand-how-resource-limits-can-affect-pod-scheduling">2.5 Understand How Resource Limits Can Affect Pod Scheduling</a><li><a href="#26-awareness-of-manifest-management-and-common-templating-tools">2.6 Awareness Of Manifest Management And Common Templating Tools</a></ul><li><a href="#objective-3-services--networking">Objective 3: Services \&amp; Networking</a><ul><li><a href="#31-understand-host-networking-configuration-on-the-cluster-nodes">3.1 Understand Host Networking Configuration On The Cluster Nodes</a><li><a href="#32-understand-connectivity-between-pods">3.2 Understand Connectivity Between Pods</a><li><a href="#33-understand-clusterip-nodeport-loadbalancer-service-types-and-endpoints">3.3 Understand ClusterIP, NodePort, LoadBalancer Service Types And Endpoints</a><ul><li><a href="#clusterip">ClusterIP</a><li><a href="#nodeport">NodePort</a><li><a href="#loadbalancer">LoadBalancer</a><li><a href="#externalip">ExternalIP</a><li><a href="#externalname">ExternalName</a><li><a href="#networking-cleanup-for-objective-33">Networking Cleanup for Objective 3.3</a></ul><li><a href="#34-know-how-to-use-ingress-controllers-and-ingress-resources">3.4 Know How To Use Ingress Controllers And Ingress Resources</a><li><a href="#35-know-how-to-configure-and-use-coredns">3.5 Know How To Configure And Use CoreDNS</a><li><a href="#36-choose-an-appropriate-container-network-interface-plugin">3.6 Choose An Appropriate Container Network Interface Plugin</a></ul><li><a href="#objective-4-storage">Objective 4: Storage</a><ul><li><a href="#41-understand-storage-classes-persistent-volumes">4.1 Understand Storage Classes, Persistent Volumes</a><ul><li><a href="#storage-classes">Storage Classes</a><li><a href="#persistent-volumes">Persistent Volumes</a></ul><li><a href="#42-understand-volume-mode-access-modes-and-reclaim-policies-for-volumes">4.2 Understand Volume Mode, Access Modes And Reclaim Policies For Volumes</a><ul><li><a href="#volume-mode">Volume Mode</a><li><a href="#access-modes">Access Modes</a><li><a href="#reclaim-policies">Reclaim Policies</a></ul><li><a href="#43-understand-persistent-volume-claims-primitive">4.3 Understand Persistent Volume Claims Primitive</a><li><a href="#44-know-how-to-configure-applications-with-persistent-storage">4.4 Know How To Configure Applications With Persistent Storage</a></ul><li><a href="#objective-5-troubleshooting">Objective 5: Troubleshooting</a><ul><li><a href="#51-evaluate-cluster-and-node-logging">5.1 Evaluate Cluster And Node Logging</a><ul><li><a href="#cluster-logging">Cluster Logging</a><li><a href="#node-logging">Node Logging</a></ul><li><a href="#52-understand-how-to-monitor-applications">5.2 Understand How To Monitor Applications</a><li><a href="#53-manage-container-stdout--stderr-logs">5.3 Manage Container Stdout \&amp; Stderr Logs</a><li><a href="#54-troubleshoot-application-failure">5.4 Troubleshoot Application Failure</a><li><a href="#55-troubleshoot-cluster-component-failure">5.5 Troubleshoot Cluster Component Failure</a><li><a href="#56-troubleshoot-networking">5.6 Troubleshoot Networking</a></ul></ul><h2 id="11-manage-role-based-access-control-rbac"> <a href="#11-manage-role-based-access-control-rbac" class="anchor-heading" aria-labelledby="11-manage-role-based-access-control-rbac"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.1 Manage Role Based Access Control (RBAC)</h2><p>Documentation and Resources:</p><ul><li><a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/">Kubectl Cheat Sheet</a><li><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/">Using RBAC Authorization</a><li><a href="https://thenewstack.io/a-practical-approach-to-understanding-kubernetes-authorization/">A Practical Approach to Understanding Kubernetes Authorization</a></ul><p>RBAC is handled by roles (permissions) and bindings (assignment of permissions to subjects):</p><div class="table-wrapper"><table><thead><tr><th>Object<th>Description<tbody><tr><td><code class="language-plaintext highlighter-rouge">Role</code><td>Permissions within a particular namespace<tr><td><code class="language-plaintext highlighter-rouge">ClusterRole</code><td>Permissions to non-namespaced resources; can be used to grant the same permissions as a Role<tr><td><code class="language-plaintext highlighter-rouge">RoleBinding</code><td>Grants the permissions defined in a role to a user or set of users<tr><td><code class="language-plaintext highlighter-rouge">ClusterRoleBinding</code><td>Grant permissions across a whole cluster</table></div><h3 id="lab-environment"> <a href="#lab-environment" class="anchor-heading" aria-labelledby="lab-environment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Lab Environment</h3><p>If desired, use a managed Kubernetes cluster, such as Amazon EKS, to immediately begin working with RBAC. The command <code class="language-plaintext highlighter-rouge">aws --region REGION eks update-kubeconfig --name CLUSTERNAME</code> will generate a .kube configuration file on your workstation to permit kubectl commands.</p><h3 id="lab-practice"> <a href="#lab-practice" class="anchor-heading" aria-labelledby="lab-practice"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Lab Practice</h3><p>Create the <code class="language-plaintext highlighter-rouge">wahlnetwork1</code> namespace.</p><p><code class="language-plaintext highlighter-rouge">kubectl create namespace wahlnetwork1</code></p><hr /><p>Create a deployment in the <code class="language-plaintext highlighter-rouge">wahlnetwork1</code> namespace using the image of your choice:</p><h1 id="kubectl-create-deployment-hello-node---imagek8sgcrioechoserver14--n-wahlnetwork1"> <a href="#kubectl-create-deployment-hello-node---imagek8sgcrioechoserver14--n-wahlnetwork1" class="anchor-heading" aria-labelledby="kubectl-create-deployment-hello-node---imagek8sgcrioechoserver14--n-wahlnetwork1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">kubectl create deployment hello-node --image=k8s.gcr.io/echoserver:1.4 -n wahlnetwork1</code></h1><h1 id="kubectl-create-deployment-busybox---imagebusybox--n-wahlnetwork1----sleep-2000"> <a href="#kubectl-create-deployment-busybox---imagebusybox--n-wahlnetwork1----sleep-2000" class="anchor-heading" aria-labelledby="kubectl-create-deployment-busybox---imagebusybox--n-wahlnetwork1----sleep-2000"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">kubectl create deployment busybox --image=busybox -n wahlnetwork1 -- sleep 2000</code></h1><p>You can view the yaml file by adding <code class="language-plaintext highlighter-rouge">--dry-run=client -o yaml</code> to the end of either deployment.</p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">hello-node</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">hello-node</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">wahlnetwork1</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">hello-node</span>
  <span class="na">strategy</span><span class="pi">:</span> <span class="pi">{}</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">hello-node</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">k8s.gcr.io/echoserver:1.4</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">echoserver</span>
          <span class="na">resources</span><span class="pi">:</span> <span class="pi">{}</span>
</code></pre></div></div><hr /><p>Create the <code class="language-plaintext highlighter-rouge">pod-reader</code> role in the <code class="language-plaintext highlighter-rouge">wahlnetwork1</code> namespace.</p><p><code class="language-plaintext highlighter-rouge">kubectl create role pod-reader --verb=get --verb=list --verb=watch --resource=pods -n wahlnetwork1</code></p><blockquote><p>Alternatively, use <code class="language-plaintext highlighter-rouge">kubectl create role pod-reader --verb=get --verb=list --verb=watch --resource=pods -n wahlnetwork1 --dry-run=client -o yaml</code> to output a proper yaml configuration.</p></blockquote><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Role</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">pod-reader</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">wahlnetwork1</span>
<span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">"</span>
    <span class="na">resources</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">pods</span>
    <span class="na">verbs</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">get</span>
      <span class="pi">-</span> <span class="s">list</span>
      <span class="pi">-</span> <span class="s">watch</span>
</code></pre></div></div><hr /><p>Create the <code class="language-plaintext highlighter-rouge">read-pods</code> rolebinding between the role named <code class="language-plaintext highlighter-rouge">pod-reader</code> and the user <code class="language-plaintext highlighter-rouge">spongebob</code> in the <code class="language-plaintext highlighter-rouge">wahlnetwork1</code> namespace.</p><p><code class="language-plaintext highlighter-rouge">kubectl create rolebinding --role=pod-reader --user=spongebob read-pods -n wahlnetwork1</code></p><blockquote><p>Alternatively, use <code class="language-plaintext highlighter-rouge">kubectl create rolebinding --role=pod-reader --user=spongebob read-pods -n wahlnetwork1 --dry-run=client -o yaml</code> to output a proper yaml configuration.</p></blockquote><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">RoleBinding</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">read-pods</span>
<span class="na">roleRef</span><span class="pi">:</span>
  <span class="na">apiGroup</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">Role</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">pod-reader</span>
<span class="na">subjects</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">apiGroup</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io</span>
    <span class="na">kind</span><span class="pi">:</span> <span class="s">User</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">spongebob</span>
</code></pre></div></div><hr /><p>Create the <code class="language-plaintext highlighter-rouge">cluster-secrets-reader</code> clusterrole.</p><p><code class="language-plaintext highlighter-rouge">kubectl create clusterrole cluster-secrets-reader --verb=get --verb=list --verb=watch --resource=secrets</code></p><blockquote><p>Alternatively, use <code class="language-plaintext highlighter-rouge">kubectl create clusterrole cluster-secrets-reader --verb=get --verb=list --verb=watch --resource=secrets --dry-run=client -o yaml</code> to output a proper yaml configuration.</p></blockquote><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRole</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">cluster-secrets-reader</span>
<span class="na">rules</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">apiGroups</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">"</span>
  <span class="na">resources</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">secrets</span>
  <span class="na">verbs</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">get</span>
  <span class="pi">-</span> <span class="s">list</span>
  <span class="pi">-</span> <span class="s">watch</span>
</code></pre></div></div><hr /><p>Create the <code class="language-plaintext highlighter-rouge">cluster-read-secrets</code> clusterrolebinding between the clusterrole named <code class="language-plaintext highlighter-rouge">cluster-secrets-reader</code> and the user <code class="language-plaintext highlighter-rouge">gizmo</code>.</p><p><code class="language-plaintext highlighter-rouge">kubectl create clusterrolebinding --clusterrole=cluster-secrets-reader --user=gizmo cluster-read-secrets</code></p><blockquote><p>Alternatively, use <code class="language-plaintext highlighter-rouge">kubectl create clusterrolebinding --clusterrole=cluster-secrets-reader --user=gizmo cluster-read-secrets --dry-run=client -o yaml</code> to output a proper yaml configuration.</p></blockquote><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRoleBinding</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">cluster-read-secrets</span>
<span class="na">roleRef</span><span class="pi">:</span>
  <span class="na">apiGroup</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterRole</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">cluster-secrets-reader</span>
<span class="na">subjects</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">apiGroup</span><span class="pi">:</span> <span class="s">rbac.authorization.k8s.io</span>
    <span class="na">kind</span><span class="pi">:</span> <span class="s">User</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">gizmo</span>
</code></pre></div></div><p>Test to see if this works by running the <code class="language-plaintext highlighter-rouge">auth</code> command.</p><p><code class="language-plaintext highlighter-rouge">kubectl auth can-i get secrets --as=gizmo</code></p><p>Attempt to get secrets as the <code class="language-plaintext highlighter-rouge">gizmo</code> user.</p><p><code class="language-plaintext highlighter-rouge">kubectl get secrets --as=gizmo</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                  TYPE                                  DATA   AGE
default-token-lz87v   kubernetes.io/service-account-token   3      7d1h
</code></pre></div></div><h2 id="12-use-kubeadm-to-install-a-basic-cluster"> <a href="#12-use-kubeadm-to-install-a-basic-cluster" class="anchor-heading" aria-labelledby="12-use-kubeadm-to-install-a-basic-cluster"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.2 Use Kubeadm to Install a Basic Cluster</h2><p>Official documentation: <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">Creating a cluster with kubeadm</a></p><blockquote><p>Terraform code is available <a href="../code/tf-cluster-asg/">here</a> to create the resources necessary to experiment with <code class="language-plaintext highlighter-rouge">kubeadm</code></p></blockquote><h3 id="kubeadm-tasks-for-all-nodes"> <a href="#kubeadm-tasks-for-all-nodes" class="anchor-heading" aria-labelledby="kubeadm-tasks-for-all-nodes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Kubeadm Tasks for All Nodes</h3><ul><li>Create Amazon EC2 Instances<ul><li>Create an AWS Launch Template using an Ubuntu 18.04 LTS image (or newer) of size <code class="language-plaintext highlighter-rouge">t3a.small</code> (2 CPU, 2 GiB Memory).<li>Disable the <a href="https://askubuntu.com/questions/214805/how-do-i-disable-swap">swap</a> file.<ul><li>Note: This can be validated by using the console command <code class="language-plaintext highlighter-rouge">free</code> when SSH’d to the instance. The swap space total should be 0.</ul><li>Consume this template as part of an Auto Scaling Group of 1 or more instances. This makes deployment of new instances and removal of old instances trivial.</ul><li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#letting-iptables-see-bridged-traffic">Configure iptables</a><ul><li>This allows iptables to see bridged traffic.</ul><li><a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#docker">Install the Docker container runtime</a><ul><li>The <a href="https://github.com/docker/docker-install">docker-install</a> script is handy for this.</ul><li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl">Install kubeadm, kubelet, and kubectl</a></ul><p>Alternatively, use a <code class="language-plaintext highlighter-rouge">user-data</code> bash script attached to the Launch Template:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="c"># Disable Swap</span>
<span class="nb">sudo </span>swapoff <span class="nt">-a</span>

<span class="c"># Bridge Network</span>
<span class="nb">sudo </span>modprobe br_netfilter
<span class="nb">sudo cat</span> <span class="o">&lt;&lt;</span><span class="sh">'</span><span class="no">EOF</span><span class="sh">' | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
</span><span class="no">EOF
</span><span class="nb">sudo </span>sysctl <span class="nt">--system</span>

<span class="c"># Install Docker</span>
<span class="nb">sudo </span>curl <span class="nt">-fsSL</span> https://get.docker.com <span class="nt">-o</span> /home/ubuntu/get-docker.sh
<span class="nb">sudo </span>sh /home/ubuntu/get-docker.sh

<span class="c"># Install Kube tools</span>
<span class="nb">sudo </span>apt-get update <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> apt-transport-https curl
curl <span class="nt">-s</span> https://packages.cloud.google.com/apt/doc/apt-key.gpg | <span class="nb">sudo </span>apt-key add -
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">'</span><span class="no">EOF</span><span class="sh">' | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
</span><span class="no">EOF
</span><span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> kubelet kubeadm kubectl
<span class="nb">sudo </span>apt-mark hold kubelet kubeadm kubectl
</code></pre></div></div><p>Optionally, add <code class="language-plaintext highlighter-rouge">sudo kubeadm config images pull</code> to the end of the script to pre-pull images required for setting up a Kubernetes cluster.</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>kubeadm config images pull

<span class="o">[</span>config/images] Pulled k8s.gcr.io/kube-apiserver:v1.19.2
<span class="o">[</span>config/images] Pulled k8s.gcr.io/kube-controller-manager:v1.19.2
<span class="o">[</span>config/images] Pulled k8s.gcr.io/kube-scheduler:v1.19.2
<span class="o">[</span>config/images] Pulled k8s.gcr.io/kube-proxy:v1.19.2
<span class="o">[</span>config/images] Pulled k8s.gcr.io/pause:3.2
<span class="o">[</span>config/images] Pulled k8s.gcr.io/etcd:3.4.13-0
<span class="o">[</span>config/images] Pulled k8s.gcr.io/coredns:1.7.0
</code></pre></div></div><h3 id="kubeadm-tasks-for-single-control-node"> <a href="#kubeadm-tasks-for-single-control-node" class="anchor-heading" aria-labelledby="kubeadm-tasks-for-single-control-node"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Kubeadm Tasks for Single Control Node</h3><ul><li>Initialize the cluster<ul><li>Choose your Container Network Interface (CNI) plugin. This guide uses <a href="https://docs.projectcalico.org/about/about-calico">Calico’s CNI</a>.<li>Run <code class="language-plaintext highlighter-rouge">sudo kubeadm init --pod-network-cidr=192.168.0.0/16</code> to initialize the cluster and provide a pod network aligned to <a href="https://docs.projectcalico.org/getting-started/kubernetes/quickstart#create-a-single-host-kubernetes-cluster">Calico’s default configuration</a>.<li>Write down the <code class="language-plaintext highlighter-rouge">kubeadm join</code> output to <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#join-nodes">join worker nodes</a> later in this guide.<ul><li>Example <code class="language-plaintext highlighter-rouge">kubeadm join 10.0.0.100:6443 --token 12345678901234567890 --discovery-token-ca-cert-hash sha256:123456789012345678901234567890123456789012345678901234567890</code></ul></ul><li><a href="https://docs.projectcalico.org/getting-started/kubernetes/quickstart">Install Calico</a><li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#optional-controlling-your-cluster-from-machines-other-than-the-control-plane-node">Configure local kubectl access</a><ul><li>This step simply copies the <code class="language-plaintext highlighter-rouge">admin.conf</code> file into a location accessible for a regular user.</ul></ul><p>Alternatively, use the <a href="https://coreos.com/flannel/docs/latest/kubernetes.html">Flannel CNI</a>.</p><ul><li>Run <code class="language-plaintext highlighter-rouge">sudo kubeadm init --pod-network-cidr=10.244.0.0/16</code> to initialize the cluster and provide a pod network aligned to <a href="https://github.com/coreos/flannel/blob/master/Documentation/kubernetes.md">Flannel’s default configuration</a>.<ul><li>Note: The <a href="https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml"><code class="language-plaintext highlighter-rouge">kube-flannel.yml</code></a> file is hosted in the same location.</ul></ul><h3 id="kubeadm-tasks-for-worker-nodes"> <a href="#kubeadm-tasks-for-worker-nodes" class="anchor-heading" aria-labelledby="kubeadm-tasks-for-worker-nodes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Kubeadm Tasks for Worker Node(s)</h3><ul><li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#join-nodes">Join the cluster</a><ul><li>Note: You can view the cluster config with <code class="language-plaintext highlighter-rouge">kubectl config view</code>. This includes the cluster server address (e.g. <code class="language-plaintext highlighter-rouge">server: https://10.0.0.100:6443</code>)</ul></ul><h3 id="kubeadm-troubleshooting"> <a href="#kubeadm-troubleshooting" class="anchor-heading" aria-labelledby="kubeadm-troubleshooting"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Kubeadm Troubleshooting</h3><ul><li>If using <code class="language-plaintext highlighter-rouge">kubeadm init</code> without a pod network CIDR the CoreDNS pods will remain <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#coredns-or-kube-dns-is-stuck-in-the-pending-state">stuck in pending state</a><li>Broke cluster and want to start over? Use <code class="language-plaintext highlighter-rouge">kubeadm reset</code> and <code class="language-plaintext highlighter-rouge">rm -rf .kube</code> in the user home directory to remove the old config and avoid <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#tls-certificate-errors">TLS certificate errors</a><li>If seeing <code class="language-plaintext highlighter-rouge">error: error loading config file "/etc/kubernetes/admin.conf": open /etc/kubernetes/admin.conf: permission denied</code> it likely means the <code class="language-plaintext highlighter-rouge">KUBECONFIG</code> variable is set to that path, try <code class="language-plaintext highlighter-rouge">unset KUBECONFIG</code> to use the <code class="language-plaintext highlighter-rouge">$HOME/.kube/config</code> file.</ul><h3 id="kubeadm-optional-tasks"> <a href="#kubeadm-optional-tasks" class="anchor-heading" aria-labelledby="kubeadm-optional-tasks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Kubeadm Optional Tasks</h3><ul><li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-windows">Install kubectl client locally on Windows</a> for those using this OS.<li>Single node cluster? <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/">Taint the control node</a> to accept pods without dedicated worker nodes.<li>Deploy the “hello-node” app from the <a href="https://kubernetes.io/docs/tutorials/hello-minikube/">minikube tutorial</a> to test basic functionality.</ul><h2 id="13-manage-a-highly-available-kubernetes-cluster"> <a href="#13-manage-a-highly-available-kubernetes-cluster" class="anchor-heading" aria-labelledby="13-manage-a-highly-available-kubernetes-cluster"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.3 Manage A Highly-Available Kubernetes Cluster</h2><p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/">High Availability Production Environment</a></p><p>Kubernetes Components for HA:</p><ul><li>Load Balancer / VIP<li>DNS records<li>etcd Endpoint<li>Certificates<li>Any HA specific queries / configuration / settings</ul><h3 id="ha-deployment-types"> <a href="#ha-deployment-types" class="anchor-heading" aria-labelledby="ha-deployment-types"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> HA Deployment Types</h3><ul><li>With stacked control plane nodes. This approach requires less infrastructure. The etcd members and control plane nodes are co-located.<li>With an external etcd cluster. This approach requires more infrastructure. The control plane nodes and etcd members are separated. (<a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/">source</a>)</ul><h3 id="upgrading-from-single-control-plane-to-high-availability"> <a href="#upgrading-from-single-control-plane-to-high-availability" class="anchor-heading" aria-labelledby="upgrading-from-single-control-plane-to-high-availability"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Upgrading from Single Control-Plane to High Availability</h3><p>If you have plans to upgrade this single control-plane kubeadm cluster to high availability you should specify the –control-plane-endpoint to set the shared endpoint for all control-plane nodes. Such an endpoint can be either a DNS name or an IP address of a load-balancer. (<a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#initializing-your-control-plane-node">source</a>)</p><h2 id="14-provision-underlying-infrastructure-to-deploy-a-kubernetes-cluster"> <a href="#14-provision-underlying-infrastructure-to-deploy-a-kubernetes-cluster" class="anchor-heading" aria-labelledby="14-provision-underlying-infrastructure-to-deploy-a-kubernetes-cluster"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.4 Provision Underlying Infrastructure to Deploy a Kubernetes Cluster</h2><p>See Objective <a href="#12-use-kubeadm-to-install-a-basic-cluster">1.2 Use Kubeadm to Install a Basic Cluster</a>.</p><blockquote><p>Note: Make sure that swap is disabled on all nodes.</p></blockquote><h2 id="15-perform-a-version-upgrade-on-a-kubernetes-cluster-using-kubeadm"> <a href="#15-perform-a-version-upgrade-on-a-kubernetes-cluster-using-kubeadm" class="anchor-heading" aria-labelledby="15-perform-a-version-upgrade-on-a-kubernetes-cluster-using-kubeadm"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.5 Perform a Version Upgrade on a Kubernetes Cluster using Kubeadm</h2><ul><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">Upgrading kubeadm clusters</a><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/">Safely Drain a Node while Respecting the PodDisruptionBudget</a><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#maintenance-on-a-node">Cluster Management: Maintenance on a Node</a></ul><blockquote><p>Note: All containers are restarted after upgrade, because the container spec hash value is changed. Upgrades are constrained from one minor version to the next minor version.</p></blockquote><h3 id="first-control-plane-node"> <a href="#first-control-plane-node" class="anchor-heading" aria-labelledby="first-control-plane-node"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> First Control Plane Node</h3><p>Update the kubeadm tool and verify the new version</p><blockquote><p>Note: The <code class="language-plaintext highlighter-rouge">--allow-change-held-packages</code> flag is used because kubeadm updates should be held to prevent automated updates.</p></blockquote><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apt-get update <span class="o">&amp;&amp;</span> <span class="se">\</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nt">--allow-change-held-packages</span> <span class="nv">kubeadm</span><span class="o">=</span>1.19.x-00
kubeadm version
</code></pre></div></div><hr /><p><a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#drain">Drain</a> the node to mark as unschedulable</p><p><code class="language-plaintext highlighter-rouge">kubectl drain $NODENAME --ignore-daemonsets</code></p><details><summary>Drain Diagram</summary> ![drain](https://kubernetes.io/images/docs/kubectl_drain.svg) </details><hr /><p>Perform an upgrade plan to validate that your cluster can be upgraded</p><blockquote><p>Note: This also fetches the versions you can upgrade to and shows a table with the component config version states.</p></blockquote><p><code class="language-plaintext highlighter-rouge">sudo kubeadm upgrade plan</code></p><hr /><p>Upgrade the cluster</p><p><code class="language-plaintext highlighter-rouge">sudo kubeadm upgrade apply v1.19.x</code></p><hr /><p><a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#uncordon">Uncordon</a> the node to mark as schedulable</p><p><code class="language-plaintext highlighter-rouge">kubectl uncordon $NODENAME</code></p><h3 id="additional-control-plane-nodes"> <a href="#additional-control-plane-nodes" class="anchor-heading" aria-labelledby="additional-control-plane-nodes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Additional Control Plane Nodes</h3><p>Repeat the first control plane node steps while replacing the “upgrade the cluster” step using the command below:</p><p><code class="language-plaintext highlighter-rouge">sudo kubeadm upgrade node</code></p><h3 id="upgrade-control-plane-node-kubectl-and-kubelet-tools"> <a href="#upgrade-control-plane-node-kubectl-and-kubelet-tools" class="anchor-heading" aria-labelledby="upgrade-control-plane-node-kubectl-and-kubelet-tools"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Upgrade Control Plane Node Kubectl And Kubelet Tools</h3><p>Upgrade the kubelet and kubectl on all control plane nodes</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apt-get update <span class="o">&amp;&amp;</span> <span class="se">\</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nt">--allow-change-held-packages</span> <span class="nv">kubelet</span><span class="o">=</span>1.19.x-00 <span class="nv">kubectl</span><span class="o">=</span>1.19.x-00
</code></pre></div></div><hr /><p>Restart the kubelet</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>systemctl daemon-reload
<span class="nb">sudo </span>systemctl restart kubelet
</code></pre></div></div><h3 id="upgrade-worker-nodes"> <a href="#upgrade-worker-nodes" class="anchor-heading" aria-labelledby="upgrade-worker-nodes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Upgrade Worker Nodes</h3><p>Upgrade kubeadm</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apt-get update <span class="o">&amp;&amp;</span> <span class="se">\</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nt">--allow-change-held-packages</span> <span class="nv">kubeadm</span><span class="o">=</span>1.19.x-00
</code></pre></div></div><hr /><p>Drain the node</p><p><code class="language-plaintext highlighter-rouge">kubectl drain $NODENAME --ignore-daemonsets</code></p><hr /><p>Upgrade the kubelet configuration</p><p><code class="language-plaintext highlighter-rouge">sudo kubeadm upgrade node</code></p><hr /><p>Upgrade kubelet and kubectl</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apt-get update <span class="o">&amp;&amp;</span> <span class="se">\</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nt">--allow-change-held-packages</span> <span class="nv">kubelet</span><span class="o">=</span>1.19.x-00 <span class="nv">kubectl</span><span class="o">=</span>1.19.x-00

<span class="nb">sudo </span>systemctl daemon-reload
<span class="nb">sudo </span>systemctl restart kubelet
</code></pre></div></div><hr /><p>Uncordon the node</p><p><code class="language-plaintext highlighter-rouge">kubectl uncordon $NODENAME</code></p><h2 id="16-implement-etcd-backup-and-restore"> <a href="#16-implement-etcd-backup-and-restore" class="anchor-heading" aria-labelledby="16-implement-etcd-backup-and-restore"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.6 Implement Etcd Backup And Restore</h2><ul><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster">Operating etcd clusters for Kubernetes: Backing up an etcd cluster</a><li><a href="https://etcd.io/docs/v3.4.0/op-guide/recovery/">Etcd Documentation: Disaster Recovery</a><li><a href="https://medium.com/better-programming/kubernetes-tips-backup-and-restore-etcd-97fe12e56c57">Kubernetes Tips: Backup and Restore Etcd</a></ul><h3 id="snapshot-the-keyspace"> <a href="#snapshot-the-keyspace" class="anchor-heading" aria-labelledby="snapshot-the-keyspace"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Snapshot The Keyspace</h3><p>Use <code class="language-plaintext highlighter-rouge">etcdctl snapshot save</code>.</p><p>Snapshot the keyspace served by $ENDPOINT to the file snapshot.db:</p><p><code class="language-plaintext highlighter-rouge">ETCDCTL_API=3 etcdctl --endpoints $ENDPOINT snapshot save snapshot.db</code></p><h3 id="restore-from-snapshot"> <a href="#restore-from-snapshot" class="anchor-heading" aria-labelledby="restore-from-snapshot"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Restore From Snapshot</h3><p>Use <code class="language-plaintext highlighter-rouge">etcdctl snapshot restore</code>.</p><blockquote><p>Note: Restoring overwrites some snapshot metadata (specifically, the member ID and cluster ID); the member loses its former identity.</p><p>Note: Snapshot integrity is verified when restoring from a snapshot using an integrity hash created by <code class="language-plaintext highlighter-rouge">etcdctl snapshot save</code>, but not when restoring from a file copy.</p></blockquote><p>Create new etcd data directories (m1.etcd, m2.etcd, m3.etcd) for a three member cluster:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ ETCDCTL_API</span><span class="o">=</span>3 etcdctl snapshot restore snapshot.db <span class="se">\</span>
  <span class="nt">--name</span> m1 <span class="se">\</span>
  <span class="nt">--initial-cluster</span> <span class="nv">m1</span><span class="o">=</span>http://host1:2380,m2<span class="o">=</span>http://host2:2380,m3<span class="o">=</span>http://host3:2380 <span class="se">\</span>
  <span class="nt">--initial-cluster-token</span> etcd-cluster-1 <span class="se">\</span>
  <span class="nt">--initial-advertise-peer-urls</span> http://host1:2380
<span class="nv">$ ETCDCTL_API</span><span class="o">=</span>3 etcdctl snapshot restore snapshot.db <span class="se">\</span>
  <span class="nt">--name</span> m2 <span class="se">\</span>
  <span class="nt">--initial-cluster</span> <span class="nv">m1</span><span class="o">=</span>http://host1:2380,m2<span class="o">=</span>http://host2:2380,m3<span class="o">=</span>http://host3:2380 <span class="se">\</span>
  <span class="nt">--initial-cluster-token</span> etcd-cluster-1 <span class="se">\</span>
  <span class="nt">--initial-advertise-peer-urls</span> http://host2:2380
<span class="nv">$ ETCDCTL_API</span><span class="o">=</span>3 etcdctl snapshot restore snapshot.db <span class="se">\</span>
  <span class="nt">--name</span> m3 <span class="se">\</span>
  <span class="nt">--initial-cluster</span> <span class="nv">m1</span><span class="o">=</span>http://host1:2380,m2<span class="o">=</span>http://host2:2380,m3<span class="o">=</span>http://host3:2380 <span class="se">\</span>
  <span class="nt">--initial-cluster-token</span> etcd-cluster-1 <span class="se">\</span>
  <span class="nt">--initial-advertise-peer-urls</span> http://host3:2380
</code></pre></div></div><h1 id="objective-2-workloads--scheduling"> <a href="#objective-2-workloads--scheduling" class="anchor-heading" aria-labelledby="objective-2-workloads--scheduling"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Objective 2: Workloads &amp; Scheduling</h1><ul><li><a href="#objective-1-cluster-architecture-installation--configuration">Objective 1: Cluster Architecture, Installation \&amp; Configuration</a><ul><li><a href="#11-manage-role-based-access-control-rbac">1.1 Manage Role Based Access Control (RBAC)</a><ul><li><a href="#lab-environment">Lab Environment</a><li><a href="#lab-practice">Lab Practice</a></ul><li><a href="#12-use-kubeadm-to-install-a-basic-cluster">1.2 Use Kubeadm to Install a Basic Cluster</a><ul><li><a href="#kubeadm-tasks-for-all-nodes">Kubeadm Tasks for All Nodes</a><li><a href="#kubeadm-tasks-for-single-control-node">Kubeadm Tasks for Single Control Node</a><li><a href="#kubeadm-tasks-for-worker-nodes">Kubeadm Tasks for Worker Node(s)</a><li><a href="#kubeadm-troubleshooting">Kubeadm Troubleshooting</a><li><a href="#kubeadm-optional-tasks">Kubeadm Optional Tasks</a></ul><li><a href="#13-manage-a-highly-available-kubernetes-cluster">1.3 Manage A Highly-Available Kubernetes Cluster</a><ul><li><a href="#ha-deployment-types">HA Deployment Types</a><li><a href="#upgrading-from-single-control-plane-to-high-availability">Upgrading from Single Control-Plane to High Availability</a></ul><li><a href="#14-provision-underlying-infrastructure-to-deploy-a-kubernetes-cluster">1.4 Provision Underlying Infrastructure to Deploy a Kubernetes Cluster</a><li><a href="#15-perform-a-version-upgrade-on-a-kubernetes-cluster-using-kubeadm">1.5 Perform a Version Upgrade on a Kubernetes Cluster using Kubeadm</a><ul><li><a href="#first-control-plane-node">First Control Plane Node</a><li><a href="#additional-control-plane-nodes">Additional Control Plane Nodes</a><li><a href="#upgrade-control-plane-node-kubectl-and-kubelet-tools">Upgrade Control Plane Node Kubectl And Kubelet Tools</a><li><a href="#upgrade-worker-nodes">Upgrade Worker Nodes</a></ul><li><a href="#16-implement-etcd-backup-and-restore">1.6 Implement Etcd Backup And Restore</a><ul><li><a href="#snapshot-the-keyspace">Snapshot The Keyspace</a><li><a href="#restore-from-snapshot">Restore From Snapshot</a></ul></ul><li><a href="#objective-2-workloads--scheduling">Objective 2: Workloads \&amp; Scheduling</a><ul><li><a href="#21-understand-deployments-and-how-to-perform-rolling-update-and-rollbacks">2.1 Understand Deployments And How To Perform Rolling Update And Rollbacks</a><ul><li><a href="#create-deployment">Create Deployment</a><li><a href="#perform-rolling-update">Perform Rolling Update</a><li><a href="#perform-rollbacks">Perform Rollbacks</a></ul><li><a href="#22-use-configmaps-and-secrets-to-configure-applications">2.2 Use Configmaps And Secrets To Configure Applications</a><ul><li><a href="#configmaps">Configmaps</a><li><a href="#secrets">Secrets</a><li><a href="#other-concepts">Other Concepts</a></ul><li><a href="#23-know-how-to-scale-applications">2.3 Know How To Scale Applications</a><li><a href="#24-understand-the-primitives-used-to-create-robust-self-healing-application-deployments">2.4 Understand The Primitives Used To Create Robust, Self-Healing, Application Deployments</a><li><a href="#25-understand-how-resource-limits-can-affect-pod-scheduling">2.5 Understand How Resource Limits Can Affect Pod Scheduling</a><li><a href="#26-awareness-of-manifest-management-and-common-templating-tools">2.6 Awareness Of Manifest Management And Common Templating Tools</a></ul><li><a href="#objective-3-services--networking">Objective 3: Services \&amp; Networking</a><ul><li><a href="#31-understand-host-networking-configuration-on-the-cluster-nodes">3.1 Understand Host Networking Configuration On The Cluster Nodes</a><li><a href="#32-understand-connectivity-between-pods">3.2 Understand Connectivity Between Pods</a><li><a href="#33-understand-clusterip-nodeport-loadbalancer-service-types-and-endpoints">3.3 Understand ClusterIP, NodePort, LoadBalancer Service Types And Endpoints</a><ul><li><a href="#clusterip">ClusterIP</a><li><a href="#nodeport">NodePort</a><li><a href="#loadbalancer">LoadBalancer</a><li><a href="#externalip">ExternalIP</a><li><a href="#externalname">ExternalName</a><li><a href="#networking-cleanup-for-objective-33">Networking Cleanup for Objective 3.3</a></ul><li><a href="#34-know-how-to-use-ingress-controllers-and-ingress-resources">3.4 Know How To Use Ingress Controllers And Ingress Resources</a><li><a href="#35-know-how-to-configure-and-use-coredns">3.5 Know How To Configure And Use CoreDNS</a><li><a href="#36-choose-an-appropriate-container-network-interface-plugin">3.6 Choose An Appropriate Container Network Interface Plugin</a></ul><li><a href="#objective-4-storage">Objective 4: Storage</a><ul><li><a href="#41-understand-storage-classes-persistent-volumes">4.1 Understand Storage Classes, Persistent Volumes</a><ul><li><a href="#storage-classes">Storage Classes</a><li><a href="#persistent-volumes">Persistent Volumes</a></ul><li><a href="#42-understand-volume-mode-access-modes-and-reclaim-policies-for-volumes">4.2 Understand Volume Mode, Access Modes And Reclaim Policies For Volumes</a><ul><li><a href="#volume-mode">Volume Mode</a><li><a href="#access-modes">Access Modes</a><li><a href="#reclaim-policies">Reclaim Policies</a></ul><li><a href="#43-understand-persistent-volume-claims-primitive">4.3 Understand Persistent Volume Claims Primitive</a><li><a href="#44-know-how-to-configure-applications-with-persistent-storage">4.4 Know How To Configure Applications With Persistent Storage</a></ul><li><a href="#objective-5-troubleshooting">Objective 5: Troubleshooting</a><ul><li><a href="#51-evaluate-cluster-and-node-logging">5.1 Evaluate Cluster And Node Logging</a><ul><li><a href="#cluster-logging">Cluster Logging</a><li><a href="#node-logging">Node Logging</a></ul><li><a href="#52-understand-how-to-monitor-applications">5.2 Understand How To Monitor Applications</a><li><a href="#53-manage-container-stdout--stderr-logs">5.3 Manage Container Stdout \&amp; Stderr Logs</a><li><a href="#54-troubleshoot-application-failure">5.4 Troubleshoot Application Failure</a><li><a href="#55-troubleshoot-cluster-component-failure">5.5 Troubleshoot Cluster Component Failure</a><li><a href="#56-troubleshoot-networking">5.6 Troubleshoot Networking</a></ul></ul><h2 id="21-understand-deployments-and-how-to-perform-rolling-update-and-rollbacks"> <a href="#21-understand-deployments-and-how-to-perform-rolling-update-and-rollbacks" class="anchor-heading" aria-labelledby="21-understand-deployments-and-how-to-perform-rolling-update-and-rollbacks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2.1 Understand Deployments And How To Perform Rolling Update And Rollbacks</h2><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#use-case">Official Documentation</a></p><p>Deployments are used to manage Pods and ReplicaSets in a declarative manner.</p><h3 id="create-deployment"> <a href="#create-deployment" class="anchor-heading" aria-labelledby="create-deployment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Create Deployment</h3><p>Using the <a href="https://hub.docker.com/_/nginx">nginx</a> image on Docker Hub, we can use a Deployment to push any number of replicas of that image to the cluster.</p><p>Create the <code class="language-plaintext highlighter-rouge">nginx</code> deployment in the <code class="language-plaintext highlighter-rouge">wahlnetwork1</code> namespace.</p><p><code class="language-plaintext highlighter-rouge">kubectl create deployment nginx --image=nginx --replicas=3 -n wahlnetwork1</code></p><blockquote><p>Alternatively, use <code class="language-plaintext highlighter-rouge">kubectl create deployment nginx --image=nginx --replicas=3 -n wahlnetwork1 --dry-run=client -o yaml</code> to output a proper yaml configuration.</p></blockquote><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">wahlnetwork1</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
  <span class="na">strategy</span><span class="pi">:</span> <span class="pi">{}</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">nginx</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
          <span class="na">resources</span><span class="pi">:</span> <span class="pi">{}</span>
</code></pre></div></div><h3 id="perform-rolling-update"> <a href="#perform-rolling-update" class="anchor-heading" aria-labelledby="perform-rolling-update"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Perform Rolling Update</h3><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#updating-a-deployment">Official Documentation</a></p><p>Used to make changes to the pod’s template and roll them out to the cluster. Triggered when data within <code class="language-plaintext highlighter-rouge">.spec.template</code> is changed.</p><p>Update the <code class="language-plaintext highlighter-rouge">nginx</code> deployment in the <code class="language-plaintext highlighter-rouge">wahlnetwork1</code> namespace to use version <code class="language-plaintext highlighter-rouge">1.16.1</code></p><p><code class="language-plaintext highlighter-rouge">kubectl set image deployment/nginx nginx=nginx:1.16.1 -n wahlnetwork1 --record</code></p><p>Track the rollout status.</p><p><code class="language-plaintext highlighter-rouge">kubectl rollout status deployment.v1.apps/nginx -n wahlnetwork1</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Waiting <span class="k">for </span>deployment <span class="s2">"nginx"</span> rollout to finish: 1 out of 2 new replicas have been updated...
Waiting <span class="k">for </span>deployment <span class="s2">"nginx"</span> rollout to finish: 1 out of 2 new replicas have been updated...
Waiting <span class="k">for </span>deployment <span class="s2">"nginx"</span> rollout to finish: 1 out of 2 new replicas have been updated...
Waiting <span class="k">for </span>deployment <span class="s2">"nginx"</span> rollout to finish: 1 old replicas are pending termination...
Waiting <span class="k">for </span>deployment <span class="s2">"nginx"</span> rollout to finish: 1 old replicas are pending termination...
deployment <span class="s2">"nginx"</span> successfully rolled out
</code></pre></div></div><h3 id="perform-rollbacks"> <a href="#perform-rollbacks" class="anchor-heading" aria-labelledby="perform-rollbacks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Perform Rollbacks</h3><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#rolling-back-a-deployment">Official Documentation</a></p><p>Rollbacks offer a method for reverting the changes to a pod’s <code class="language-plaintext highlighter-rouge">.spec.template</code> data to a previous version. By default, executing the <code class="language-plaintext highlighter-rouge">rollout undo</code> command will revert to the previous version. The desired version can also be declared.</p><p>Review the version history for the <code class="language-plaintext highlighter-rouge">nginx</code> deployment in the <code class="language-plaintext highlighter-rouge">wahlnetwork1</code> namespace. In this scenario, other revisions 1-4 have been made to simulate a deployment lifecycle. The 4th revision specifies a fake image version of <code class="language-plaintext highlighter-rouge">1.222222222222</code> to force a rolling update failure.</p><p><code class="language-plaintext highlighter-rouge">kubectl rollout history deployment.v1.apps/nginx -n wahlnetwork1</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>deployment.apps/nginx
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         kubectl.exe <span class="nb">set </span>image deployment/nginx <span class="nv">nginx</span><span class="o">=</span>nginx:1.16.1 <span class="nt">--record</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--namespace</span><span class="o">=</span>wahlnetwork1
3         kubectl.exe <span class="nb">set </span>image deployment/nginx <span class="nv">nginx</span><span class="o">=</span>nginx:1.14.1 <span class="nt">--record</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--namespace</span><span class="o">=</span>wahlnetwork1
4         kubectl.exe <span class="nb">set </span>image deployment/nginx <span class="nv">nginx</span><span class="o">=</span>nginx:1.222222222222 <span class="nt">--record</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--namespace</span><span class="o">=</span>wahlnetwork1
</code></pre></div></div><p>Revert to the previous version of the <code class="language-plaintext highlighter-rouge">nginx</code> deployment to use image version <code class="language-plaintext highlighter-rouge">1.14.1</code>. This forces revision 3 to become revision # Note that revision 3 no longer exists.</p><p><code class="language-plaintext highlighter-rouge">kubectl rollout undo deployment.v1.apps/nginx -n wahlnetwork1</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>deployment.apps/nginx rolled back

~ kubectl rollout <span class="nb">history </span>deployment.v1.apps/nginx <span class="nt">-n</span> wahlnetwork1

deployment.apps/nginx
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         kubectl.exe <span class="nb">set </span>image deployment/nginx <span class="nv">nginx</span><span class="o">=</span>nginx:1.16.1 <span class="nt">--record</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--namespace</span><span class="o">=</span>wahlnetwork1
4         kubectl.exe <span class="nb">set </span>image deployment/nginx <span class="nv">nginx</span><span class="o">=</span>nginx:1.222222222222 <span class="nt">--record</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--namespace</span><span class="o">=</span>wahlnetwork1
5         kubectl.exe <span class="nb">set </span>image deployment/nginx <span class="nv">nginx</span><span class="o">=</span>nginx:1.14.1 <span class="nt">--record</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--namespace</span><span class="o">=</span>wahlnetwork1
</code></pre></div></div><p>Revert to revision 2 of the <code class="language-plaintext highlighter-rouge">nginx</code> deployment, which becomes revision 6 (the next available revision number). Note that revision 2 no longer exists.</p><p><code class="language-plaintext highlighter-rouge">kubectl rollout undo deployment.v1.apps/nginx -n wahlnetwork1 --to-revision=2</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~ kubectl rollout <span class="nb">history </span>deployment.v1.apps/nginx <span class="nt">-n</span> wahlnetwork1

deployment.apps/nginx
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
4         kubectl.exe <span class="nb">set </span>image deployment/nginx <span class="nv">nginx</span><span class="o">=</span>nginx:1.222222222222 <span class="nt">--record</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--namespace</span><span class="o">=</span>wahlnetwork1
5         kubectl.exe <span class="nb">set </span>image deployment/nginx <span class="nv">nginx</span><span class="o">=</span>nginx:1.14.1 <span class="nt">--record</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--namespace</span><span class="o">=</span>wahlnetwork1
6         kubectl.exe <span class="nb">set </span>image deployment/nginx <span class="nv">nginx</span><span class="o">=</span>nginx:1.16.1 <span class="nt">--record</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--namespace</span><span class="o">=</span>wahlnetwork1
</code></pre></div></div><h2 id="22-use-configmaps-and-secrets-to-configure-applications"> <a href="#22-use-configmaps-and-secrets-to-configure-applications" class="anchor-heading" aria-labelledby="22-use-configmaps-and-secrets-to-configure-applications"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2.2 Use Configmaps And Secrets To Configure Applications</h2><h3 id="configmaps"> <a href="#configmaps" class="anchor-heading" aria-labelledby="configmaps"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Configmaps</h3><p>API object used to store non-confidential data in key-value pairs</p><ul><li><a href="https://kubernetes.io/docs/concepts/configuration/configmap/">Official Documentation</a> <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/">Configure a Pod to Use a ConfigMap</a></ul><p>Create a configmap named <code class="language-plaintext highlighter-rouge">game-config</code> using a directory.</p><p><code class="language-plaintext highlighter-rouge">kubectl create configmap game-config --from-file=/code/configmap/</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~ k describe configmap game-config

Name:         game-config
Namespace:    default
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;

Data
<span class="o">====</span>
game.properties:
<span class="nt">----</span>
<span class="nv">enemies</span><span class="o">=</span>aliens
<span class="nv">lives</span><span class="o">=</span>3
enemies.cheat<span class="o">=</span><span class="nb">true
</span>enemies.cheat.level<span class="o">=</span>noGoodRotten
secret.code.passphrase<span class="o">=</span>UUDDLRLRBABAS
secret.code.allowed<span class="o">=</span><span class="nb">true
</span>secret.code.lives<span class="o">=</span>30

ui.properties:
<span class="nt">----</span>
color.good<span class="o">=</span>purple
color.bad<span class="o">=</span>yellow
allow.textmode<span class="o">=</span><span class="nb">true
</span>how.nice.to.look<span class="o">=</span>fairlyNice

Events:  &lt;none&gt;
</code></pre></div></div><p>Create a configmap named <code class="language-plaintext highlighter-rouge">game-config</code> using a file.</p><p><code class="language-plaintext highlighter-rouge">kubectl create configmap game-config-2 --from-file=/code/configmap/game.properties</code></p><p>Create a configmap named <code class="language-plaintext highlighter-rouge">game-config</code> using an env-file.</p><p><code class="language-plaintext highlighter-rouge">kubectl create configmap game-config-env-file --from-env-file=/code/configmap/game-env-file.properties</code></p><p>Create a configmap named <code class="language-plaintext highlighter-rouge">special-config</code> using a literal key/value pair.</p><p><code class="language-plaintext highlighter-rouge">kubectl create configmap special-config --from-literal=special.how=very</code></p><p>Edit a configmap named <code class="language-plaintext highlighter-rouge">game-config</code>.</p><p><code class="language-plaintext highlighter-rouge">kubectl edit configmap game-config</code></p><p>Get a configmap named <code class="language-plaintext highlighter-rouge">game-config</code> and output the response into yaml.</p><p><code class="language-plaintext highlighter-rouge">kubectl get configmaps game-config -o yaml</code></p><p>Use a configmap with a pod by declaring a value for <code class="language-plaintext highlighter-rouge">.spec.containers.env.name.valueFrom.configMapKeyRef</code>.</p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">dapi-test-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">test-container</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">k8s.gcr.io/busybox</span>
      <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">/bin/sh"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">-c"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">env"</span><span class="pi">]</span>
      <span class="na">env</span><span class="pi">:</span>
        <span class="c1"># Define the environment variable</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">SPECIAL_LEVEL_KEY</span>
          <span class="na">valueFrom</span><span class="pi">:</span>
            <span class="na">configMapKeyRef</span><span class="pi">:</span>
              <span class="c1"># The ConfigMap containing the value you want to assign to SPECIAL_LEVEL_KEY</span>
              <span class="na">name</span><span class="pi">:</span> <span class="s">special-config</span>
              <span class="c1"># Specify the key associated with the value</span>
              <span class="na">key</span><span class="pi">:</span> <span class="s">special.how</span>
  <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Never</span>
</code></pre></div></div><p>Investigate the configmap value <code class="language-plaintext highlighter-rouge">very</code> from the key <code class="language-plaintext highlighter-rouge">SPECIAL_LEVEL_KEY</code> by reviewing the logs for the pod or by connecting to the pod directly.</p><p><code class="language-plaintext highlighter-rouge">kubectl exec -n wahlnetwork1 --stdin nginx-6889dfccd5-msmn8 --tty -- /bin/bash</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~ kubectl logs dapi-test-pod

<span class="nv">KUBERNETES_SERVICE_PORT</span><span class="o">=</span>443
<span class="nv">KUBERNETES_PORT</span><span class="o">=</span>tcp://10.96.0.1:443
<span class="nv">HOSTNAME</span><span class="o">=</span>dapi-test-pod
<span class="nv">SHLVL</span><span class="o">=</span>1
<span class="nv">HOME</span><span class="o">=</span>/root
<span class="nv">KUBERNETES_PORT_443_TCP_ADDR</span><span class="o">=</span>10.96.0.1
<span class="nv">PATH</span><span class="o">=</span>/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
<span class="nv">KUBERNETES_PORT_443_TCP_PORT</span><span class="o">=</span>443
<span class="nv">KUBERNETES_PORT_443_TCP_PROTO</span><span class="o">=</span>tcp
<span class="nv">SPECIAL_LEVEL_KEY</span><span class="o">=</span>very
<span class="nv">KUBERNETES_PORT_443_TCP</span><span class="o">=</span>tcp://10.96.0.1:443
<span class="nv">KUBERNETES_SERVICE_PORT_HTTPS</span><span class="o">=</span>443
<span class="nv">PWD</span><span class="o">=</span>/
<span class="nv">KUBERNETES_SERVICE_HOST</span><span class="o">=</span>10.96.0.1
</code></pre></div></div><h3 id="secrets"> <a href="#secrets" class="anchor-heading" aria-labelledby="secrets"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Secrets</h3><ul><li><a href="https://kubernetes.io/docs/tasks/configmap-secret/managing-secret-using-kubectl/">Managing Secret using kubectl</a><li><a href="https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets">Using Secrets</a></ul><p>Create a secret named <code class="language-plaintext highlighter-rouge">db-user-pass</code> using files.</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl create secret generic db-user-pass <span class="sb">`</span>
  <span class="nt">--from-file</span><span class="o">=</span>./username.txt <span class="sb">`</span>
  <span class="nt">--from-file</span><span class="o">=</span>./password.txt
</code></pre></div></div><p>The key name can be modified by inserting a key name into the file path. For example, setting the key names to <code class="language-plaintext highlighter-rouge">funusername</code> and <code class="language-plaintext highlighter-rouge">funpassword</code> can be done as shown below:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl create secret generic fundb-user-pass <span class="sb">`</span>
  <span class="nt">--from-file</span><span class="o">=</span><span class="nv">funusername</span><span class="o">=</span>./username.txt <span class="sb">`</span>
  <span class="nt">--from-file</span><span class="o">=</span><span class="nv">funpassword</span><span class="o">=</span>./password.txt
</code></pre></div></div><p>Check to make sure the key names matches the defined names.</p><p><code class="language-plaintext highlighter-rouge">kubectl describe secret fundb-user-pass</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name:         fundb-user-pass
Namespace:    default
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;

Type:  Opaque

Data
<span class="o">====</span>
funpassword:  14 bytes
funusername:  7 bytes
</code></pre></div></div><p>Get secret values from <code class="language-plaintext highlighter-rouge">db-user-pass</code>.</p><p><code class="language-plaintext highlighter-rouge">kubectl get secret db-user-pass -o jsonpath='{.data}'</code></p><p>Edit secret values using the <code class="language-plaintext highlighter-rouge">edit</code> command.</p><p><code class="language-plaintext highlighter-rouge">kubectl edit secrets db-user-pass</code></p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="na">password.txt</span><span class="pi">:</span> <span class="s">PASSWORD</span>
  <span class="na">username.txt</span><span class="pi">:</span> <span class="s">USERNAME</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Secret</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2020-10-13T22:48:27Z"</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">db-user-pass</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">default</span>
  <span class="na">resourceVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">1022459"</span>
  <span class="na">selfLink</span><span class="pi">:</span> <span class="s">/api/v1/namespaces/default/secrets/db-user-pass</span>
  <span class="na">uid</span><span class="pi">:</span> <span class="s">6bb24810-dd33-4b92-9a37-424f3c7553b6</span>
<span class="na">type</span><span class="pi">:</span> <span class="s">Opaque</span>
</code></pre></div></div><p>Use a secret with a pod by declaring a value for <code class="language-plaintext highlighter-rouge">.spec.containers.env.name.valueFrom.secretKeyRef</code>.</p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">secret-env-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">mycontainer</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">redis</span>
      <span class="na">env</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">SECRET_USERNAME</span>
          <span class="na">valueFrom</span><span class="pi">:</span>
            <span class="na">secretKeyRef</span><span class="pi">:</span>
              <span class="na">name</span><span class="pi">:</span> <span class="s">mysecret</span>
              <span class="na">key</span><span class="pi">:</span> <span class="s">username</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">SECRET_PASSWORD</span>
          <span class="na">valueFrom</span><span class="pi">:</span>
            <span class="na">secretKeyRef</span><span class="pi">:</span>
              <span class="na">name</span><span class="pi">:</span> <span class="s">mysecret</span>
              <span class="na">key</span><span class="pi">:</span> <span class="s">password</span>
  <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Never</span>
</code></pre></div></div><h3 id="other-concepts"> <a href="#other-concepts" class="anchor-heading" aria-labelledby="other-concepts"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Other Concepts</h3><ul><li><a href="https://kubernetes.io/docs/concepts/configuration/secret/#using-imagepullsecrets">Using imagePullSecrets</a></ul><h2 id="23-know-how-to-scale-applications"> <a href="#23-know-how-to-scale-applications" class="anchor-heading" aria-labelledby="23-know-how-to-scale-applications"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2.3 Know How To Scale Applications</h2><p>Scaling is accomplished by changing the number of replicas in a Deployment.</p><ul><li><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/scale/scale-intro/">Running Multiple Instances of Your App</a></ul><p>Scale a deployment named <code class="language-plaintext highlighter-rouge">nginx</code> from 3 to 4 replicas.</p><p><code class="language-plaintext highlighter-rouge">kubectl scale deployments/nginx --replicas=4</code></p><h2 id="24-understand-the-primitives-used-to-create-robust-self-healing-application-deployments"> <a href="#24-understand-the-primitives-used-to-create-robust-self-healing-application-deployments" class="anchor-heading" aria-labelledby="24-understand-the-primitives-used-to-create-robust-self-healing-application-deployments"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2.4 Understand The Primitives Used To Create Robust, Self-Healing, Application Deployments</h2><ul><li>Don’t use naked Pods (that is, Pods not bound to a ReplicaSet or Deployment) if you can avoid it. Naked Pods will not be rescheduled in the event of a node failure. (<a href="https://kubernetes.io/docs/concepts/configuration/overview/#naked-pods-vs-replicasets-deployments-and-jobs">source</a>)<li>A Deployment, which both creates a ReplicaSet to ensure that the desired number of Pods is always available, and specifies a strategy to replace Pods (such as RollingUpdate), is almost always preferable to creating Pods directly, except for some explicit <code class="language-plaintext highlighter-rouge">restartPolicy: Never</code> scenarios. A Job may also be appropriate. (<a href="https://kubernetes.io/docs/concepts/configuration/overview/#naked-pods-vs-replicasets-deployments-and-jobs">source</a>)<li>Define and use labels that identify semantic attributes of your application or Deployment, such as <code class="language-plaintext highlighter-rouge">{ app: myapp, tier: frontend, phase: test, deployment: v3 }</code>. (<a href="https://kubernetes.io/docs/concepts/configuration/overview/#using-labels">source</a>)</ul><h2 id="25-understand-how-resource-limits-can-affect-pod-scheduling"> <a href="#25-understand-how-resource-limits-can-affect-pod-scheduling" class="anchor-heading" aria-labelledby="25-understand-how-resource-limits-can-affect-pod-scheduling"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2.5 Understand How Resource Limits Can Affect Pod Scheduling</h2><p>Resource limits are a mechanism to control the amount of resources needed by a container. This commonly translates into CPU and memory limits.</p><ul><li>Limits set an upper boundary on the amount of resources a container is allowed to consume from the host.<li>Requests set an upper boundary on the amount of resources a container is allowed to consume from the host.<li>If a limit is set without a request, the request value is set to equal the limit value.<li><a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">Managing Resources for Containers</a><li><a href="https://kubernetes.io/docs/concepts/policy/resource-quotas/">Resource Quotas</a></ul><p>Here is an example of pod configured with resource requests and limits.</p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">frontend</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">app</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">images.my-company.example/app:v4</span>
      <span class="na">resources</span><span class="pi">:</span>
        <span class="na">requests</span><span class="pi">:</span>
          <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">64Mi"</span>
          <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">250m"</span>
        <span class="na">limits</span><span class="pi">:</span>
          <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">128Mi"</span>
          <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">500m"</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">log-aggregator</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">images.my-company.example/log-aggregator:v6</span>
      <span class="na">resources</span><span class="pi">:</span>
        <span class="na">requests</span><span class="pi">:</span>
          <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">64Mi"</span>
          <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">250m"</span>
        <span class="na">limits</span><span class="pi">:</span>
          <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">128Mi"</span>
          <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">500m"</span>
</code></pre></div></div><h2 id="26-awareness-of-manifest-management-and-common-templating-tools"> <a href="#26-awareness-of-manifest-management-and-common-templating-tools" class="anchor-heading" aria-labelledby="26-awareness-of-manifest-management-and-common-templating-tools"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2.6 Awareness Of Manifest Management And Common Templating Tools</h2><ul><li><a href="https://learnk8s.io/templating-yaml-with-code">Templating YAML in Kubernetes with real code</a><li><a href="https://github.com/kislyuk/yq">yq</a>: Command-line YAML/XML processor<li><a href="https://github.com/kubernetes-sigs/kustomize">kustomize</a>: lets you customize raw, template-free YAML files for multiple purposes, leaving the original YAML untouched and usable as is.<li><a href="https://github.com/helm/helm">Helm</a>: A tool for managing Charts. Charts are packages of pre-configured Kubernetes resources.</ul><h1 id="objective-3-services--networking"> <a href="#objective-3-services--networking" class="anchor-heading" aria-labelledby="objective-3-services--networking"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Objective 3: Services &amp; Networking</h1><ul><li><a href="#objective-3-services--networking">Objective 3: Services &amp; Networking</a><ul><li><a href="#31-understand-host-networking-configuration-on-the-cluster-nodes">3.1 Understand Host Networking Configuration On The Cluster Nodes</a><li><a href="#32-understand-connectivity-between-pods">3.2 Understand Connectivity Between Pods</a><li><a href="#33-understand-clusterip-nodeport-loadbalancer-service-types-and-endpoints">3.3 Understand ClusterIP, NodePort, LoadBalancer Service Types And Endpoints</a><ul><li><a href="#clusterip">ClusterIP</a><li><a href="#nodeport">NodePort</a><li><a href="#loadbalancer">LoadBalancer</a><li><a href="#externalip">ExternalIP</a><li><a href="#externalname">ExternalName</a><li><a href="#networking-cleanup-for-objective-33">Networking Cleanup for Objective 3.3</a></ul><li><a href="#34-know-how-to-use-ingress-controllers-and-ingress-resources">3.4 Know How To Use Ingress Controllers And Ingress Resources</a><li><a href="#35-know-how-to-configure-and-use-coredns">3.5 Know How To Configure And Use CoreDNS</a><li><a href="#36-choose-an-appropriate-container-network-interface-plugin">3.6 Choose An Appropriate Container Network Interface Plugin</a></ul></ul><blockquote><p>Note: If you need access to the pod network while working through the networking examples, use the <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/">Get a Shell to a Running Container</a> guide to deploy a shell container. I often like to have a tab open to the shell container to run arbitrary network commands without the need to <code class="language-plaintext highlighter-rouge">exec</code> in and out of it repeatedly.</p></blockquote><h2 id="31-understand-host-networking-configuration-on-the-cluster-nodes"> <a href="#31-understand-host-networking-configuration-on-the-cluster-nodes" class="anchor-heading" aria-labelledby="31-understand-host-networking-configuration-on-the-cluster-nodes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3.1 Understand Host Networking Configuration On The Cluster Nodes</h2><ul><li><p>Design</p><ul><li>All nodes can talk<li>All pods can talk (without NAT)<li>Every pod gets a unique IP address</ul><li><p>Network Types</p><ul><li>Pod Network<li>Node Network<li>Services Network<ul><li>Rewrites egress traffic destined to a service network endpoint with a pod network IP address</ul></ul><li><p>Proxy Modes</p><ul><li>IPTables Mode<ul><li>The standard mode<li><code class="language-plaintext highlighter-rouge">kube-proxy</code> watches the Kubernetes control plane for the addition and removal of Service and Endpoint objects<li>For each Service, it installs iptables rules, which capture traffic to the Service’s clusterIP and port, and redirect that traffic to one of the Service’s backend sets.<li>For each Endpoint object, it installs iptables rules which select a backend Pod.<li><a href="https://kubernetes.io/docs/concepts/services-networking/service/#proxy-mode-iptables">Official Documentation</a><li><a href="https://www.stackrox.com/post/2020/01/kubernetes-networking-demystified/">Kubernetes Networking Demystified: A Brief Guide</a></ul><li>IPVS Mode<ul><li>Since 1.11<li>Linux IP Virtual Server (IPVS)<li>L4 load balancer</ul></ul></ul><h2 id="32-understand-connectivity-between-pods"> <a href="#32-understand-connectivity-between-pods" class="anchor-heading" aria-labelledby="32-understand-connectivity-between-pods"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3.2 Understand Connectivity Between Pods</h2><p><a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/">Official Documentation</a></p><p>Read <a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/#the-kubernetes-network-model">The Kubernetes network model</a>:</p><ul><li>Every pod gets its own address<li>Fundamental requirements on any networking implementation<ul><li>Pods on a node can communicate with all pods on all nodes without NAT<li>Agents on a node (e.g. system daemons, kubelet) can communicate with all pods on that node<li>Pods in the host network of a node can communicate with all pods on all nodes without NAT</ul><li>Kubernetes IP addresses exist at the Pod scope<ul><li>Containers within a pod can communicate with one another over <code class="language-plaintext highlighter-rouge">localhost</code><li>“IP-per-pod” model</ul></ul><h2 id="33-understand-clusterip-nodeport-loadbalancer-service-types-and-endpoints"> <a href="#33-understand-clusterip-nodeport-loadbalancer-service-types-and-endpoints" class="anchor-heading" aria-labelledby="33-understand-clusterip-nodeport-loadbalancer-service-types-and-endpoints"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3.3 Understand ClusterIP, NodePort, LoadBalancer Service Types And Endpoints</h2><p>Services are all about abstracting away the details of which pods are running behind a particular network endpoint. For many applications, work must be processed by some other service. Using a service allows the application to “toss over” the work to Kubernetes, which then uses a selector to determine which pods are healthy and available to receive the work. The service abstracts numerous replica pods that are available to do work.</p><ul><li><a href="https://kubernetes.io/docs/concepts/services-networking/service/">Official Documentation</a><li><a href="https://www.katacoda.com/courses/kubernetes/networking-introduction">Katakoda Networking Introduction</a></ul><blockquote><p>Note: This section was completed using a GKE cluster and may differ from what your cluster looks like.</p></blockquote><h3 id="clusterip"> <a href="#clusterip" class="anchor-heading" aria-labelledby="clusterip"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ClusterIP</h3><ul><li>Exposes the Service on a cluster-internal IP.<li>Choosing this value makes the Service only reachable from within the cluster.<li>This is the default ServiceType.<li><a href="https://kubernetes.io/docs/tutorials/services/source-ip/">Using Source IP</a><li><a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#expose">Kubectl Expose Command Reference</a></ul><p>The imperative option is to create a deployment and then expose the deployment. In this example, the deployment is exposed using a ClusterIP service that accepts traffic on port 80 and translates it to the pod using port 8080.</p><p><code class="language-plaintext highlighter-rouge">kubectl create deployment funkyapp1 --image=k8s.gcr.io/echoserver:1.4</code></p><p><code class="language-plaintext highlighter-rouge">kubectl expose deployment funkyapp1 --name=funkyip --port=80 --target-port=8080 --type=ClusterIP</code></p><blockquote><p>Note: The <code class="language-plaintext highlighter-rouge">--type=ClusterIP</code> parameter is optional when deploying a <code class="language-plaintext highlighter-rouge">ClusterIP</code> service since this is the default type.</p></blockquote><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">funkyapp1</span> <span class="c1">#Selector</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">funkyip</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
      <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
      <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">funkyapp1</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">ClusterIP</span> <span class="c1">#Note this!</span>
</code></pre></div></div><p>Using <code class="language-plaintext highlighter-rouge">kubectl describe svc funkyip</code> shows more details:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name:              funkyip
Namespace:         default
Labels:            <span class="nv">app</span><span class="o">=</span>funkyapp1
Annotations:       cloud.google.com/neg: <span class="o">{</span><span class="s2">"ingress"</span>:true<span class="o">}</span>
Selector:          <span class="nv">app</span><span class="o">=</span>funkyapp1
Type:              ClusterIP
IP:                10.108.3.156
Port:              &lt;<span class="nb">unset</span><span class="o">&gt;</span>  80/TCP
TargetPort:        8080/TCP
Endpoints:         10.104.2.7:8080
Session Affinity:  None
Events:            &lt;none&gt;
</code></pre></div></div><hr /><p>Check to make sure the <code class="language-plaintext highlighter-rouge">funkyip</code> service exists. This also shows the assigned service (cluster IP) address.</p><p><code class="language-plaintext highlighter-rouge">kubectl get svc funkyip</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>   AGE
funkyip      ClusterIP   10.108.3.156   &lt;none&gt;        80/TCP    21m
</code></pre></div></div><hr /><p>From there, you can see the endpoint created to match any pod discovered using the <code class="language-plaintext highlighter-rouge">app: funkyapp1</code> label.</p><p><code class="language-plaintext highlighter-rouge">kubectl get endpoints funkyip</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME         ENDPOINTS           AGE
funkyip      10.104.2.7:8080     21m
</code></pre></div></div><hr /><p>The endpoint matches the IP address of the matching pod.</p><p><code class="language-plaintext highlighter-rouge">kubectl get pods -o wide</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                         READY   STATUS    RESTARTS   AGE     IP            NODE                                                NOMINATED NODE   READINESS GATES
funkyapp1-7b478ccf9b-2vlc2   1/1     Running   0          21m     10.104.2.7    gke-my-first-cluster-1-default-pool-504c1e77-zg6v   &lt;none&gt;           &lt;none&gt;
shell-demo                   1/1     Running   0          3m12s   10.128.0.14   gke-my-first-cluster-1-default-pool-504c1e77-m9lk   &lt;none&gt;           &lt;none&gt;
</code></pre></div></div><hr /><p>The <code class="language-plaintext highlighter-rouge">.spec.ports.port</code> value defines the port used to access the service. The <code class="language-plaintext highlighter-rouge">.spec.ports.targetPort</code> value defines the port used to access the container’s application.</p><p><code class="language-plaintext highlighter-rouge">User -&gt; Port -&gt; Kubernetes Service -&gt; Target Port -&gt; Application</code></p><p>This can be tested using <code class="language-plaintext highlighter-rouge">curl</code>:</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">CLUSTER_IP</span><span class="o">=</span><span class="si">$(</span>kubectl get services/funkyip <span class="nt">-o</span> go-template<span class="o">=</span><span class="s1">'(index .spec.clusterIP)'</span><span class="si">)</span>
<span class="nb">echo </span><span class="nv">CLUSTER_IP</span><span class="o">=</span><span class="nv">$CLUSTER_IP</span>
</code></pre></div></div><p>From there, use <code class="language-plaintext highlighter-rouge">curl $CLUSTER_IP:80</code> to hit the service <code class="language-plaintext highlighter-rouge">port</code>, which redirects to the <code class="language-plaintext highlighter-rouge">targetPort</code> of 8080.</p><p><code class="language-plaintext highlighter-rouge">curl 10.108.3.156:80</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CLIENT VALUES:
<span class="nv">client_address</span><span class="o">=</span>10.128.0.14
<span class="nb">command</span><span class="o">=</span>GET
real <span class="nv">path</span><span class="o">=</span>/
<span class="nv">query</span><span class="o">=</span>nil
<span class="nv">request_version</span><span class="o">=</span>1.1
<span class="nv">request_uri</span><span class="o">=</span>http://10.108.3.156:8080/

SERVER VALUES:
<span class="nv">server_version</span><span class="o">=</span>nginx: 1.10.0 - lua: 10001

HEADERS RECEIVED:
<span class="nv">accept</span><span class="o">=</span><span class="k">*</span>/<span class="k">*</span>
<span class="nv">host</span><span class="o">=</span>10.108.3.156
user-agent<span class="o">=</span>curl/7.64.0
BODY:
<span class="nt">-no</span> body <span class="k">in </span>request-root
</code></pre></div></div><h3 id="nodeport"> <a href="#nodeport" class="anchor-heading" aria-labelledby="nodeport"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> NodePort</h3><ul><li>Exposes the Service on each Node’s IP at a static port (the NodePort).<li><a href="https://kubernetes.io/docs/concepts/services-networking/service/#nodeport">Official Documentation</a></ul><p><code class="language-plaintext highlighter-rouge">kubectl expose deployment funkyapp1 --name=funkynode --port=80 --target-port=8080 --type=NodePort</code></p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">funkyapp1</span> <span class="c1">#Selector</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">funkynode</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
      <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
      <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">funkyapp1</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">NodePort</span> <span class="c1">#Note this!</span>
</code></pre></div></div><hr /><p>This service is available on each node at a specific port.</p><p><code class="language-plaintext highlighter-rouge">kubectl describe svc funkynode</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name:                     funkynode
Namespace:                default
Labels:                   <span class="nv">app</span><span class="o">=</span>funkyapp1
Annotations:              cloud.google.com/neg: <span class="o">{</span><span class="s2">"ingress"</span>:true<span class="o">}</span>
Selector:                 <span class="nv">app</span><span class="o">=</span>funkyapp1
Type:                     NodePort
IP:                       10.108.5.37
Port:                     &lt;<span class="nb">unset</span><span class="o">&gt;</span>  80/TCP
TargetPort:               8080/TCP
NodePort:                 &lt;<span class="nb">unset</span><span class="o">&gt;</span>  30182/TCP
Endpoints:                10.104.2.7:8080
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   &lt;none&gt;
</code></pre></div></div><hr /><p>By using the node IP address with the <code class="language-plaintext highlighter-rouge">nodePort</code> value, we can see the desired payload. Make sure to scale the deployment so that each node is running one replica of the pod. For a cluster with 2 worker nodes, this can be done with <code class="language-plaintext highlighter-rouge">kubectl scale deploy funkyapp1 --replicas=3</code>.</p><p>From there, it is possible to <code class="language-plaintext highlighter-rouge">curl</code> directly to a node IP address using the <code class="language-plaintext highlighter-rouge">nodePort</code> when using the shell pod demo. If working from outside the pod network, use the service IP address.</p><p><code class="language-plaintext highlighter-rouge">curl 10.128.0.14:30182</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CLIENT VALUES:
<span class="nv">client_address</span><span class="o">=</span>10.128.0.14
<span class="nb">command</span><span class="o">=</span>GET
real <span class="nv">path</span><span class="o">=</span>/
<span class="nv">query</span><span class="o">=</span>nil
<span class="nv">request_version</span><span class="o">=</span>1.1
<span class="nv">request_uri</span><span class="o">=</span>http://10.128.0.14:8080/

SERVER VALUES:
<span class="nv">server_version</span><span class="o">=</span>nginx: 1.10.0 - lua: 10001

HEADERS RECEIVED:
<span class="nv">accept</span><span class="o">=</span><span class="k">*</span>/<span class="k">*</span>
<span class="nv">host</span><span class="o">=</span>10.128.0.14:30182
user-agent<span class="o">=</span>curl/7.64.0
BODY:
<span class="nt">-no</span> body <span class="k">in </span>request-root
</code></pre></div></div><h3 id="loadbalancer"> <a href="#loadbalancer" class="anchor-heading" aria-labelledby="loadbalancer"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> LoadBalancer</h3><ul><li>Exposes the Service externally using a cloud provider’s load balancer.<li>NodePort and ClusterIP Services, to which the external load balancer routes, are automatically created.<li><a href="https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-type-loadbalancer">Source IP for Services with Type LoadBalancer</a></ul><p><code class="language-plaintext highlighter-rouge">kubectl expose deployment funkyapp1 --name=funkylb --port=80 --target-port=8080 --type=LoadBalancer</code></p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="kc">null</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">funkyapp1</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">funkylb</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
      <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
      <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">funkyapp1</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">LoadBalancer</span> <span class="c1">#Note this!</span>
</code></pre></div></div><hr /><p>Get information on the <code class="language-plaintext highlighter-rouge">funkylb</code> service to determine the External IP address.</p><p><code class="language-plaintext highlighter-rouge">kubectl get svc funkylb</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME      TYPE           CLUSTER-IP      EXTERNAL-IP     PORT<span class="o">(</span>S<span class="o">)</span>        AGE
funkylb   LoadBalancer   10.108.11.148   35.232.149.96   80:31679/TCP   64s
</code></pre></div></div><p>It is then possible to retrieve the payload using the External IP address and port value from anywhere on the Internet; no need to use the pod shell demo!</p><p><code class="language-plaintext highlighter-rouge">curl 35.232.149.96:80</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CLIENT VALUES:
<span class="nv">client_address</span><span class="o">=</span>10.104.2.1
<span class="nb">command</span><span class="o">=</span>GET
real <span class="nv">path</span><span class="o">=</span>/
<span class="nv">query</span><span class="o">=</span>nil
<span class="nv">request_version</span><span class="o">=</span>1.1
<span class="nv">request_uri</span><span class="o">=</span>http://35.232.149.96:8080/

SERVER VALUES:
<span class="nv">server_version</span><span class="o">=</span>nginx: 1.10.0 - lua: 10001

HEADERS RECEIVED:
<span class="nv">accept</span><span class="o">=</span><span class="k">*</span>/<span class="k">*</span>
<span class="nv">host</span><span class="o">=</span>35.232.149.96
user-agent<span class="o">=</span>curl/7.55.1
BODY:
<span class="nt">-no</span> body <span class="k">in </span>request-
</code></pre></div></div><h3 id="externalip"> <a href="#externalip" class="anchor-heading" aria-labelledby="externalip"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ExternalIP</h3><p><a href="https://kubernetes.io/docs/concepts/services-networking/service/#external-ips">Official Documentation</a></p><ul><li>Exposes a Kubernetes service on an external IP address.<li>Kubernetes has no control over this external IP address.</ul><p>Here is an example spec:</p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-service</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">MyApp</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">http</span>
      <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
      <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
      <span class="na">targetPort</span><span class="pi">:</span> <span class="m">9376</span>
  <span class="na">externalIPs</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">80.11.12.10</span> <span class="c1">#Take note!</span>
</code></pre></div></div><h3 id="externalname"> <a href="#externalname" class="anchor-heading" aria-labelledby="externalname"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ExternalName</h3><ul><li>Maps the Service to the contents of the externalName field (e.g. foo.bar.example.com), by returning a CNAME record with its value.<li>No proxy of any kind is set up.</ul><h3 id="networking-cleanup-for-objective-33"> <a href="#networking-cleanup-for-objective-33" class="anchor-heading" aria-labelledby="networking-cleanup-for-objective-33"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Networking Cleanup for Objective 3.3</h3><p>Run these commands to cleanup the resources, if desired.</p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl delete svc funkyip
kubectl delete svc funkynode
kubectl delete svc funkylb
kubectl delete deploy funkyapp1
</code></pre></div></div><h2 id="34-know-how-to-use-ingress-controllers-and-ingress-resources"> <a href="#34-know-how-to-use-ingress-controllers-and-ingress-resources" class="anchor-heading" aria-labelledby="34-know-how-to-use-ingress-controllers-and-ingress-resources"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3.4 Know How To Use Ingress Controllers And Ingress Resources</h2><p>Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster.</p><ul><li>Traffic routing is controlled by rules defined on the <strong>Ingress resource</strong>.<li>An <strong>Ingress controller</strong> is responsible for fulfilling the Ingress, usually with a load balancer, though it may also configure your edge router or additional frontends to help handle the traffic.<ul><li>For example, the <a href="https://www.nginx.com/products/nginx/kubernetes-ingress-controller">NGINX Ingress Controller for Kubernetes</a></ul><li>The name of an Ingress object must be a valid DNS subdomain name.<li><a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress Documentation</a><li>A list of <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/">Ingress Controllers</a><li><a href="https://www.katacoda.com/courses/kubernetes/create-kubernetes-ingress-routes">Katacoda - Create Ingress Routing</a> lab<li><a href="https://www.katacoda.com/javajon/courses/kubernetes-applications/nginx">Katacoda - Nginx on Kubernetes</a> lab</ul><p>Example of an ingress resource:</p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Ingress</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">minimal-ingress</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="na">nginx.ingress.kubernetes.io/rewrite-target</span><span class="pi">:</span> <span class="s">/</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">rules</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">http</span><span class="pi">:</span>
        <span class="na">paths</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/testpath</span>
            <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
            <span class="na">backend</span><span class="pi">:</span>
              <span class="na">service</span><span class="pi">:</span>
                <span class="na">name</span><span class="pi">:</span> <span class="s">test</span>
                <span class="na">port</span><span class="pi">:</span>
                  <span class="na">number</span><span class="pi">:</span> <span class="m">80</span>
</code></pre></div></div><p>Information on some of the objects within this resource:</p><ul><li><a href="https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules">Ingress Rules</a><li><a href="https://kubernetes.io/docs/concepts/services-networking/ingress/#path-types">Path Types</a></ul><p>And, in the case of Nginx, <a href="https://octopus.com/blog/nginx-ingress-crds">a custom resource definition (CRD) is often used</a> to extend the usefulness of an ingress. An example is shown below:</p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">k8s.nginx.org/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualServer</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">cafe</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">host</span><span class="pi">:</span> <span class="s">cafe.example.com</span>
  <span class="na">tls</span><span class="pi">:</span>
    <span class="na">secret</span><span class="pi">:</span> <span class="s">cafe-secret</span>
  <span class="na">upstreams</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">tea</span>
      <span class="na">service</span><span class="pi">:</span> <span class="s">tea-svc</span>
      <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">coffee</span>
      <span class="na">service</span><span class="pi">:</span> <span class="s">coffee-svc</span>
      <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
  <span class="na">routes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/tea</span>
      <span class="na">action</span><span class="pi">:</span>
        <span class="na">pass</span><span class="pi">:</span> <span class="s">tea</span>
    <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/coffee</span>
      <span class="na">action</span><span class="pi">:</span>
        <span class="na">pass</span><span class="pi">:</span> <span class="s">coffee</span>
</code></pre></div></div><h2 id="35-know-how-to-configure-and-use-coredns"> <a href="#35-know-how-to-configure-and-use-coredns" class="anchor-heading" aria-labelledby="35-know-how-to-configure-and-use-coredns"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3.5 Know How To Configure And Use CoreDNS</h2><p>CoreDNS is a general-purpose authoritative DNS server that can serve as cluster DNS.</p><ul><li>A bit of history:<ul><li>As of Kubernetes v1.12, CoreDNS is the recommended DNS Server, replacing <code class="language-plaintext highlighter-rouge">kube-dns</code>.<li>In Kubernetes version 1.13 and later the CoreDNS feature gate is removed and CoreDNS is used by default.<li>In Kubernetes 1.18, <code class="language-plaintext highlighter-rouge">kube-dns</code> usage with kubeadm has been deprecated and will be removed in a future version.</ul><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/coredns/">Using CoreDNS for Service Discovery</a><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/">Customizing DNS Service</a></ul><p>CoreDNS is installed with the following default <a href="https://coredns.io/2017/07/23/corefile-explained/">Corefile</a> configuration:</p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ConfigMap</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">coredns</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">kube-system</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="na">Corefile</span><span class="pi">:</span> <span class="pi">|</span>
    <span class="s">.:53 {</span>
        <span class="s">errors</span>
        <span class="s">health {</span>
            <span class="s">lameduck 5s</span>
        <span class="s">}</span>
        <span class="s">ready</span>
        <span class="s">kubernetes cluster.local in-addr.arpa ip6.arpa {</span>
            <span class="s">pods insecure</span>
            <span class="s">fallthrough in-addr.arpa ip6.arpa</span>
            <span class="s">ttl 30</span>
        <span class="s">}</span>
        <span class="s">prometheus :9153</span>
        <span class="s">forward . /etc/resolv.conf</span>
        <span class="s">cache 30</span>
        <span class="s">loop</span>
        <span class="s">reload</span>
        <span class="s">loadbalance</span>
    <span class="s">}</span>
</code></pre></div></div><p>If you need to customize CoreDNS behavior, you create and apply your own ConfigMap to override settings in the Corefile. The <a href="https://docs.cloud.oracle.com/en-us/iaas/Content/ContEng/Tasks/contengconfiguringdnsserver.htm">Configuring DNS Servers for Kubernetes Clusters</a> document describes this in detail.</p><hr /><p>Review your configmaps for the <code class="language-plaintext highlighter-rouge">kube-system</code> namespace to determine if there is a <code class="language-plaintext highlighter-rouge">coredns-custom</code> configmap.</p><p><code class="language-plaintext highlighter-rouge">kubectl get configmaps --namespace=kube-system</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                 DATA   AGE
cluster-kubestore                    0      23h
clustermetrics                       0      23h
extension-apiserver-authentication   6      24h
gke-common-webhook-lock              0      23h
ingress-gce-lock                     0      23h
ingress-uid                          2      23h
kube-dns                             0      23h
kube-dns-autoscaler                  1      23h
metrics-server-config                1      23h
</code></pre></div></div><hr /><p>Create a file named <code class="language-plaintext highlighter-rouge">coredns.yml</code> containing a configmap with the desired DNS entries in the <code class="language-plaintext highlighter-rouge">data</code> field such as the example below:</p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ConfigMap</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">coredns-custom</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">kube-system</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="na">example.server</span><span class="pi">:</span>
    <span class="pi">|</span> <span class="c1"># All custom server files must have a “.server” file extension.</span>
    <span class="s"># Change example.com to the domain you wish to forward.</span>
    <span class="s">example.com {</span>
      <span class="s"># Change 1.1.1.1 to your customer DNS resolver.</span>
      <span class="s">forward . 1.1.1.1</span>
    <span class="s">}</span>
</code></pre></div></div><hr /><p>Apply the configmap.</p><p><code class="language-plaintext highlighter-rouge">kubectl apply -f coredns.yml</code></p><hr /><p>Validate the existence of the <code class="language-plaintext highlighter-rouge">coredns-custom</code> configmap.</p><p><code class="language-plaintext highlighter-rouge">kubectl get configmaps --namespace=kube-system</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                 DATA   AGE
cluster-kubestore                    0      24h
clustermetrics                       0      24h
coredns-custom                       1      6s
extension-apiserver-authentication   6      24h
gke-common-webhook-lock              0      24h
ingress-gce-lock                     0      24h
ingress-uid                          2      24h
kube-dns                             0      24h
kube-dns-autoscaler                  1      24h
metrics-server-config                1      24h
</code></pre></div></div><hr /><p>Get the configmap and output the value in yaml format.</p><p><code class="language-plaintext highlighter-rouge">kubectl get configmaps --namespace=kube-system coredns-custom -o yaml</code></p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="na">example.server</span><span class="pi">:</span> <span class="pi">|</span>
    <span class="s"># Change example.com to the domain you wish to forward.</span>
    <span class="s">example.com {</span>
      <span class="s"># Change 1.1.1.1 to your customer DNS resolver.</span>
      <span class="s">forward . 1.1.1.1</span>
    <span class="s">}</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ConfigMap</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="na">kubectl.kubernetes.io/last-applied-configuration</span><span class="pi">:</span> <span class="pi">|</span>
      <span class="s">{"apiVersion":"v1","data":{"example.server":"# Change example.com to the domain you wish to forward.\nexample.com {\n  # Change 1.1.1.1 to your customer DNS resolver.\n  forward . 1.1.1.1\n}\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"coredns-custom","namespace":"kube-system"}}</span>
  <span class="na">creationTimestamp</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2020-10-27T19:49:24Z"</span>
  <span class="na">managedFields</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
      <span class="na">fieldsType</span><span class="pi">:</span> <span class="s">FieldsV1</span>
      <span class="na">fieldsV1</span><span class="pi">:</span>
        <span class="na">f:data</span><span class="pi">:</span>
          <span class="na">.</span><span class="pi">:</span> <span class="pi">{}</span>
          <span class="na">f:example.server</span><span class="pi">:</span> <span class="pi">{}</span>
        <span class="na">f:metadata</span><span class="pi">:</span>
          <span class="na">f:annotations</span><span class="pi">:</span>
            <span class="na">.</span><span class="pi">:</span> <span class="pi">{}</span>
            <span class="na">f:kubectl.kubernetes.io/last-applied-configuration</span><span class="pi">:</span> <span class="pi">{}</span>
      <span class="na">manager</span><span class="pi">:</span> <span class="s">kubectl-client-side-apply</span>
      <span class="na">operation</span><span class="pi">:</span> <span class="s">Update</span>
      <span class="na">time</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2020-10-27T19:49:24Z"</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">coredns-custom</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">kube-system</span>
  <span class="na">resourceVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">519480"</span>
  <span class="na">selfLink</span><span class="pi">:</span> <span class="s">/api/v1/namespaces/kube-system/configmaps/coredns-custom</span>
  <span class="na">uid</span><span class="pi">:</span> <span class="s">8d3250a5-cbb4-4f01-aae3-4e83bd158ebe</span>
</code></pre></div></div><h2 id="36-choose-an-appropriate-container-network-interface-plugin"> <a href="#36-choose-an-appropriate-container-network-interface-plugin" class="anchor-heading" aria-labelledby="36-choose-an-appropriate-container-network-interface-plugin"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3.6 Choose An Appropriate Container Network Interface Plugin</h2><p>Generally, it seems that Flannel is good for starting out in a very simplified environment, while Calico (and others) extend upon the basic functionality to meet design-specific requirements.</p><ul><li><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/">Network Plugins</a><li><a href="https://chrislovecnm.com/kubernetes/cni/choosing-a-cni-provider/">Choosing a CNI Network Provider for Kubernetes</a><li><a href="https://rancher.com/blog/2019/2019-03-21-comparing-kubernetes-cni-providers-flannel-calico-canal-and-weave/">Comparing Kubernetes CNI Providers: Flannel, Calico, Canal, and Weave</a></ul><p>Common decision points include:</p><ul><li>Network Model: Layer 2, Layer 3, VXLAN, etc.<li>Routing: Routing and route distribution for pod traffic between nodes<li>Network Policy: Essentially the firewall between network / pod segments<li>IP Address Management (IPAM)<li>Datastore:<ul><li><code class="language-plaintext highlighter-rouge">etcd</code> - for direct connection to an etcd cluster<li>Kubernetes - for connection to a Kubernetes API server</ul></ul><h1 id="objective-4-storage"> <a href="#objective-4-storage" class="anchor-heading" aria-labelledby="objective-4-storage"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Objective 4: Storage</h1><ul><li><a href="#objective-4-storage">Objective 4: Storage</a><ul><li><a href="#41-understand-storage-classes-persistent-volumes">4.1 Understand Storage Classes, Persistent Volumes</a><ul><li><a href="#storage-classes">Storage Classes</a><li><a href="#persistent-volumes">Persistent Volumes</a></ul><li><a href="#42-understand-volume-mode-access-modes-and-reclaim-policies-for-volumes">4.2 Understand Volume Mode, Access Modes And Reclaim Policies For Volumes</a><ul><li><a href="#volume-mode">Volume Mode</a><li><a href="#access-modes">Access Modes</a><li><a href="#reclaim-policies">Reclaim Policies</a></ul><li><a href="#43-understand-persistent-volume-claims-primitive">4.3 Understand Persistent Volume Claims Primitive</a><li><a href="#44-know-how-to-configure-applications-with-persistent-storage">4.4 Know How To Configure Applications With Persistent Storage</a></ul></ul><h2 id="41-understand-storage-classes-persistent-volumes"> <a href="#41-understand-storage-classes-persistent-volumes" class="anchor-heading" aria-labelledby="41-understand-storage-classes-persistent-volumes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4.1 Understand Storage Classes, Persistent Volumes</h2><ul><li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/">Storage Classes</a><li><a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">Persistent Volumes</a></ul><h3 id="storage-classes"> <a href="#storage-classes" class="anchor-heading" aria-labelledby="storage-classes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Storage Classes</h3><ul><li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#reclaim-policy">Reclaim Policy</a>: PersistentVolumes that are dynamically created by a StorageClass will have the reclaim policy specified in the reclaimPolicy field of the class<ul><li>Delete: When PersistentVolumeClaim is deleted, also deletes PersistentVolume and underlying storage object<li>Retain: When PersistentVolumeClaim is deleted, PersistentVolume remains and volume is “released”</ul><li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#volume-binding-mode">Volume Binding Mode</a>:<ul><li><code class="language-plaintext highlighter-rouge">Immediate</code>: By default, the <code class="language-plaintext highlighter-rouge">Immediate</code> mode indicates that volume binding and dynamic provisioning occurs once the PersistentVolumeClaim is created<li><code class="language-plaintext highlighter-rouge">WaitForFirstConsumer</code>: Delay the binding and provisioning of a PersistentVolume until a Pod using the PersistentVolumeClaim is created<ul><li>Supported by <code class="language-plaintext highlighter-rouge">AWSElasticBlockStore</code>, <code class="language-plaintext highlighter-rouge">GCEPersistentDisk</code>, and <code class="language-plaintext highlighter-rouge">AzureDisk</code></ul></ul><li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#allow-volume-expansion">Allow Volume Expansion</a>: Allow volumes to be expanded<ul><li>Note: It is not possible to reduce the size of a PersistentVolume</ul><li>Default Storage Class: A default storage class is used when a PersistentVolumeClaim does not specify the storage class<ul><li>Can be handy when a single default services all pod volumes</ul><li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner">Provisioner</a><ul><li>Determines the volume plugin to use for provisioning PVs.<li>Example: <code class="language-plaintext highlighter-rouge">gke-pd</code>, <code class="language-plaintext highlighter-rouge">azure-disk</code></ul></ul><hr /><p>View all storage classes</p><p><code class="language-plaintext highlighter-rouge">kubectl get storageclass</code> or <code class="language-plaintext highlighter-rouge">kubectl get sc</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                 PROVISIONER            RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
standard <span class="o">(</span>default<span class="o">)</span>   kubernetes.io/gce-pd   Delete          Immediate           <span class="nb">true                   </span>25h
</code></pre></div></div><hr /><p>View the storage class in yaml format</p><p><code class="language-plaintext highlighter-rouge">kubectl get sc standard -o yaml</code></p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">allowVolumeExpansion</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">standard</span>
<span class="na">parameters</span><span class="pi">:</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">pd-standard</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">kubernetes.io/gce-pd</span>
<span class="na">reclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>
<span class="na">volumeBindingMode</span><span class="pi">:</span> <span class="s">Immediate</span>
</code></pre></div></div><hr /><p>Make a custom storage class using the yaml configuration below and save it as <code class="language-plaintext highlighter-rouge">speedyssdclass.yaml</code></p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">allowVolumeExpansion</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">speedyssdclass</span>
<span class="na">parameters</span><span class="pi">:</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">pd-ssd</span> <span class="c1"># Note: This will use SSD backed disks</span>
  <span class="na">fstype</span><span class="pi">:</span> <span class="s">ext4</span>
  <span class="na">replication-type</span><span class="pi">:</span> <span class="s">none</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">kubernetes.io/gce-pd</span>
<span class="na">reclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>
<span class="na">volumeBindingMode</span><span class="pi">:</span> <span class="s">Immediate</span>
</code></pre></div></div><hr /><p>Apply the storage class configuration to the cluster</p><p><code class="language-plaintext highlighter-rouge">kubectl apply -f speedyssdclass.yaml</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>storageclass.storage.k8s.io/speedyssdclass created
</code></pre></div></div><hr /><p>Get the storage classes</p><p><code class="language-plaintext highlighter-rouge">kubectl get sc</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                 PROVISIONER            RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
speedyssdclass       kubernetes.io/gce-pd   Retain          WaitForFirstConsumer   <span class="nb">true                   </span>5m19s
standard <span class="o">(</span>default<span class="o">)</span>   kubernetes.io/gce-pd   Delete          Immediate              <span class="nb">true                   </span>8d
</code></pre></div></div><h3 id="persistent-volumes"> <a href="#persistent-volumes" class="anchor-heading" aria-labelledby="persistent-volumes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Persistent Volumes</h3><p>View a persistent volume in yaml format</p><p><code class="language-plaintext highlighter-rouge">kubectl get pv pvc-d2f6e37e-277f-4b7b-8725-542609f1dea4 -o yaml</code></p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolume</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">pvc-d2f6e37e-277f-4b7b-8725-542609f1dea4</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">capacity</span><span class="pi">:</span>
    <span class="na">storage</span><span class="pi">:</span> <span class="s">1Gi</span>
  <span class="na">persistentVolumeReclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">standard</span>
  <span class="na">volumeMode</span><span class="pi">:</span> <span class="s">Filesystem</span>
</code></pre></div></div><hr /><p>Create a new disk named <code class="language-plaintext highlighter-rouge">pv100</code> in Google Cloud to be used as a persistent volume</p><blockquote><p>Note: Use the zone of your GKE cluster</p></blockquote><p><code class="language-plaintext highlighter-rouge">gcloud compute disks create pv100 --size 10GiB --zone=us-central1-c</code></p><hr /><p>Make a custom persistent volume using the yaml configuration below and save it as <code class="language-plaintext highlighter-rouge">pv100.yaml</code></p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolume</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">pv100</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">capacity</span><span class="pi">:</span>
    <span class="na">storage</span><span class="pi">:</span> <span class="s">1Gi</span>
  <span class="na">persistentVolumeReclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">standard</span>
  <span class="na">volumeMode</span><span class="pi">:</span> <span class="s">Filesystem</span>
  <span class="na">gcePersistentDisk</span><span class="pi">:</span> <span class="c1"># This section is required since we are not using a Storage Class</span>
    <span class="na">fsType</span><span class="pi">:</span> <span class="s">ext4</span>
    <span class="na">pdName</span><span class="pi">:</span> <span class="s">pv100</span>
</code></pre></div></div><hr /><p>Apply the persistent volume to the cluster</p><p><code class="language-plaintext highlighter-rouge">kubectl apply -f pv100.yaml</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>persistentvolume/pv100 created
</code></pre></div></div><hr /><p>Get the persistent volume and notice that it has a status of <code class="language-plaintext highlighter-rouge">Available</code> since there is no <code class="language-plaintext highlighter-rouge">PersistentVolumeClaim</code> to bind against</p><p><code class="language-plaintext highlighter-rouge">kubectl get pv pv100</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME    CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
pv100   1Gi        RWO            Delete           Available           standard                2m51s
</code></pre></div></div><h2 id="42-understand-volume-mode-access-modes-and-reclaim-policies-for-volumes"> <a href="#42-understand-volume-mode-access-modes-and-reclaim-policies-for-volumes" class="anchor-heading" aria-labelledby="42-understand-volume-mode-access-modes-and-reclaim-policies-for-volumes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4.2 Understand Volume Mode, Access Modes And Reclaim Policies For Volumes</h2><ul><li><a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#volume-mode">Volume Mode</a><li><a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes">Access Modes</a><li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#reclaim-policy">Reclaim Policy</a></ul><h3 id="volume-mode"> <a href="#volume-mode" class="anchor-heading" aria-labelledby="volume-mode"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Volume Mode</h3><ul><li>Filesystem: Kubernetes formats the volume and presents it to a specified mount point.<ul><li>If the volume is backed by a block device and the device is empty, Kuberneretes creates a filesystem on the device before mounting it for the first time.</ul><li>Block: Kubernetes exposes a raw block device to the container.<ul><li>Improved time to usage and perhaps performance.<li>The container must know what to do with the device; there is no filesystem.</ul><li>Defined in <code class="language-plaintext highlighter-rouge">.spec.volumeMode</code> for a <code class="language-plaintext highlighter-rouge">PersistentVolumeClaim</code>.</ul><hr /><p>View the volume mode for persistent volume claims using the <code class="language-plaintext highlighter-rouge">-o wide</code> to see the <code class="language-plaintext highlighter-rouge">VOLUMEMODE</code> column</p><p><code class="language-plaintext highlighter-rouge">kubectl get pvc -o wide</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE   VOLUMEMODE
www-web-0   Bound    pvc-f3e92637-7e0d-46a3-ad87-ef1275bb5a72   1Gi        RWO            standard       19m   Filesystem
www-web-1   Bound    pvc-d2f6e37e-277f-4b7b-8725-542609f1dea4   1Gi        RWO            standard       19m   Filesystem
</code></pre></div></div><h3 id="access-modes"> <a href="#access-modes" class="anchor-heading" aria-labelledby="access-modes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Access Modes</h3><ul><li>ReadWriteOnce (RWO): can be mounted as read-write by a single node<li>ReadOnlyMany (ROX): can be mounted as read-only by many nodes<li>ReadWriteMany (RWX): can be mounted as read-write by many nodes<li>Defined in <code class="language-plaintext highlighter-rouge">.spec.accessModes</code> for a <code class="language-plaintext highlighter-rouge">PersistentVolumeClaim</code> and <code class="language-plaintext highlighter-rouge">PersistentVolume</code></ul><p>View the access mode for persistent volume claims</p><p><code class="language-plaintext highlighter-rouge">kubectl get pvc</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
www-web-0   Bound    pvc-f3e92637-7e0d-46a3-ad87-ef1275bb5a72   1Gi        RWO            standard       28m
www-web-1   Bound    pvc-d2f6e37e-277f-4b7b-8725-542609f1dea4   1Gi        RWO            standard       27m
</code></pre></div></div><h3 id="reclaim-policies"> <a href="#reclaim-policies" class="anchor-heading" aria-labelledby="reclaim-policies"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Reclaim Policies</h3><ul><li><a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#reclaim-policy">Reclaim Policy</a>: PersistentVolumes that are dynamically created by a StorageClass will have the reclaim policy specified in the reclaimPolicy field of the class<ul><li>Delete: When PersistentVolumeClaim is deleted, also deletes PersistentVolume and underlying storage object<li>Retain: When PersistentVolumeClaim is deleted, PersistentVolume remains and volume is “released”</ul><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/change-pv-reclaim-policy/">Change the Reclaim Policy of a PersistentVolume</a><li>Defined in <code class="language-plaintext highlighter-rouge">.spec.persistentVolumeReclaimPolicy</code> for <code class="language-plaintext highlighter-rouge">PersistentVolume</code>.</ul><hr /><p>View the reclaim policy set on persistent volumes</p><p><code class="language-plaintext highlighter-rouge">kubectl get pv</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM               STORAGECLASS   REASON   AGE
pvc-d2f6e37e-277f-4b7b-8725-542609f1dea4   1Gi        RWO            Delete           Bound    default/www-web-1   standard                45m
pvc-f3e92637-7e0d-46a3-ad87-ef1275bb5a72   1Gi        RWO            Delete           Bound    default/www-web-0   standard                45m
</code></pre></div></div><h2 id="43-understand-persistent-volume-claims-primitive"> <a href="#43-understand-persistent-volume-claims-primitive" class="anchor-heading" aria-labelledby="43-understand-persistent-volume-claims-primitive"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4.3 Understand Persistent Volume Claims Primitive</h2><p>Make a custom persistent volume claim using the yaml configuration below and save it as <code class="language-plaintext highlighter-rouge">pvc01.yaml</code></p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">pvc01</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">standard</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">3Gi</span>
</code></pre></div></div><hr /><p>Apply the persistent volume claim</p><p><code class="language-plaintext highlighter-rouge">kubectl apply -f pvc01.yaml</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>persistentvolumeclaim/pvc01 created
</code></pre></div></div><hr /><p>Get the persistent volume claim</p><p><code class="language-plaintext highlighter-rouge">kubectl get pvc pvc01</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc01   Bound    pvc-9f2e7c5d-b64c-467e-bba6-86ccb333d981   3Gi        RWO            standard       5m19s
</code></pre></div></div><h2 id="44-know-how-to-configure-applications-with-persistent-storage"> <a href="#44-know-how-to-configure-applications-with-persistent-storage" class="anchor-heading" aria-labelledby="44-know-how-to-configure-applications-with-persistent-storage"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4.4 Know How To Configure Applications With Persistent Storage</h2><ul><li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/">Configure a Pod to Use a PersistentVolume for Storage</a></ul><hr /><p>Create a new yaml file using the configuration below and save it as <code class="language-plaintext highlighter-rouge">pv-pod.yaml</code></p><blockquote><p>Note: Make sure to create <code class="language-plaintext highlighter-rouge">pvc01</code> in <a href="#43-understand-persistent-volume-claims-primitive">this earlier step</a></p></blockquote><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">pv-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">volumes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">pv-pod-storage</span> <span class="c1"># The name of the volume, used by .spec.containers.volumeMounts.name</span>
      <span class="na">persistentVolumeClaim</span><span class="pi">:</span>
        <span class="na">claimName</span><span class="pi">:</span> <span class="s">pvc01</span> <span class="c1"># This pvc was created in an earlier step</span>
  <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">pv-pod-container</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">nginx</span>
      <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">80</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">http-server"</span>
      <span class="na">volumeMounts</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/usr/share/nginx/html"</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">pv-pod-storage</span> <span class="c1"># This refers back to .spec.volumes.name</span>
</code></pre></div></div><hr /><p>Apply the pod</p><p><code class="language-plaintext highlighter-rouge">kubectl apply -f pv-pod.yaml</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pod/pv-pod created
</code></pre></div></div><hr /><p>Watch the pod provisioning process</p><p><code class="language-plaintext highlighter-rouge">kubectl get pod -w pv-pod</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME     READY   STATUS    RESTARTS   AGE
pv-pod   1/1     Running   0          30s
</code></pre></div></div><hr /><p>View the binding on <code class="language-plaintext highlighter-rouge">pvc01</code></p><p><code class="language-plaintext highlighter-rouge">kubectl describe pvc pvc01</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name:          pvc01
Namespace:     default
StorageClass:  standard
Status:        Bound
Volume:        pvc-9f2e7c5d-b64c-467e-bba6-86ccb333d981
Labels:        &lt;none&gt;
Annotations:   pv.kubernetes.io/bind-completed: <span class="nb">yes
               </span>pv.kubernetes.io/bound-by-controller: <span class="nb">yes
               </span>volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/gce-pd
Finalizers:    <span class="o">[</span>kubernetes.io/pvc-protection]
Capacity:      3Gi
Access Modes:  RWO
VolumeMode:    Filesystem
Mounted By:    pv-pod <span class="c"># Here it is!</span>
Events:
  Type    Reason                 Age   From                         Message
  <span class="nt">----</span>    <span class="nt">------</span>                 <span class="nt">----</span>  <span class="nt">----</span>                         <span class="nt">-------</span>
  Normal  ProvisioningSucceeded  36m   persistentvolume-controller  Successfully provisioned volume pvc-9f2e7c5d-b64c-467e-bba6-86ccb333d981 using kubernetes.io/gce-pd
</code></pre></div></div><h1 id="objective-5-troubleshooting"> <a href="#objective-5-troubleshooting" class="anchor-heading" aria-labelledby="objective-5-troubleshooting"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Objective 5: Troubleshooting</h1><ul><li><p><a href="https://learnk8s.io/troubleshooting-deployments">Troubleshooting Kubernetes deployments</a></p><li><p><a href="#objective-5-troubleshooting">Objective 5: Troubleshooting</a></p><ul><li><a href="#51-evaluate-cluster-and-node-logging">5.1 Evaluate Cluster And Node Logging</a><ul><li><a href="#cluster-logging">Cluster Logging</a><li><a href="#node-logging">Node Logging</a></ul><li><a href="#52-understand-how-to-monitor-applications">5.2 Understand How To Monitor Applications</a><li><a href="#53-manage-container-stdout--stderr-logs">5.3 Manage Container Stdout &amp; Stderr Logs</a><li><a href="#54-troubleshoot-application-failure">5.4 Troubleshoot Application Failure</a><li><a href="#55-troubleshoot-cluster-component-failure">5.5 Troubleshoot Cluster Component Failure</a><li><a href="#56-troubleshoot-networking">5.6 Troubleshoot Networking</a></ul></ul><h2 id="51-evaluate-cluster-and-node-logging"> <a href="#51-evaluate-cluster-and-node-logging" class="anchor-heading" aria-labelledby="51-evaluate-cluster-and-node-logging"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.1 Evaluate Cluster And Node Logging</h2><h3 id="cluster-logging"> <a href="#cluster-logging" class="anchor-heading" aria-labelledby="cluster-logging"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Cluster Logging</h3><p>Having a separate storage location for cluster component logging, such as nodes, pods, and applications.</p><ul><li><a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/#cluster-level-logging-architectures">Cluster-level logging architectures</a><li><a href="https://platform9.com/blog/kubernetes-logging-best-practices/">Kubernetes Logging Best Practices</a></ul><p>Commonly deployed in one of three ways:</p><h1 id="logging-agent-on-each-node-that-sends-log-data-to-a-backend-storage-repository"> <a href="#logging-agent-on-each-node-that-sends-log-data-to-a-backend-storage-repository" class="anchor-heading" aria-labelledby="logging-agent-on-each-node-that-sends-log-data-to-a-backend-storage-repository"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/#using-a-node-logging-agent">Logging agent on each node</a> that sends log data to a backend storage repository</h1><p># These agents can be deployed using a DaemonSet replica to ensure nodes have the agent running # Note: This approach only works for applications’ standard output (<em>stdout</em>) and standard error (<em>stderr</em>)</p><h1 id="logging-agent-as-a-sidecar-to-specific-deployments-that-sends-log-data-to-a-backend-storage-repository"> <a href="#logging-agent-as-a-sidecar-to-specific-deployments-that-sends-log-data-to-a-backend-storage-repository" class="anchor-heading" aria-labelledby="logging-agent-as-a-sidecar-to-specific-deployments-that-sends-log-data-to-a-backend-storage-repository"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/#using-a-sidecar-container-with-the-logging-agent">Logging agent as a sidecar</a> to specific deployments that sends log data to a backend storage repository</h1><p># Note: Writing logs to a file and then streaming them to stdout can double disk usage</p><h1 id="configure-the-containerized-application-to-send-log-data-to-a-backend-storage-repository"> <a href="#configure-the-containerized-application-to-send-log-data-to-a-backend-storage-repository" class="anchor-heading" aria-labelledby="configure-the-containerized-application-to-send-log-data-to-a-backend-storage-repository"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/#exposing-logs-directly-from-the-application">Configure the containerized application</a> to send log data to a backend storage repository</h1><h3 id="node-logging"> <a href="#node-logging" class="anchor-heading" aria-labelledby="node-logging"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Node Logging</h3><p>Having a log file on the node that is populated with standard output (<em>stdout</em>) and standard error (<em>stderr</em>) log entries from containers running on the node.</p><ul><li><a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/#logging-at-the-node-level">Logging at the node level</a></ul><h2 id="52-understand-how-to-monitor-applications"> <a href="#52-understand-how-to-monitor-applications" class="anchor-heading" aria-labelledby="52-understand-how-to-monitor-applications"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.2 Understand How To Monitor Applications</h2><ul><li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application-introspection/#using-kubectl-describe-pod-to-fetch-details-about-pods">Using kubectl describe pod to fetch details about pods</a><li><a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/#interacting-with-running-pods">Interacting with running Pods</a></ul><h2 id="53-manage-container-stdout--stderr-logs"> <a href="#53-manage-container-stdout--stderr-logs" class="anchor-heading" aria-labelledby="53-manage-container-stdout--stderr-logs"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.3 Manage Container Stdout &amp; Stderr Logs</h2><ul><li><a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs">Kubectl Commands - Logs</a><li><a href="https://cloud.google.com/blog/products/management-tools/finding-your-gke-logs">How to find—and use—your GKE logs with Cloud Logging</a><li><a href="https://vividcode.io/enable-log-rotation-in-kubernetes-cluster/">Enable Log Rotation in Kubernetes Cluster</a></ul><p><code class="language-plaintext highlighter-rouge">kubectl logs [-f] [-p] (POD | TYPE/NAME) [-c CONTAINER]</code></p><ul><li><code class="language-plaintext highlighter-rouge">-f</code> will follow the logs<li><code class="language-plaintext highlighter-rouge">-p</code> will pull up the previous instance of the container<li><code class="language-plaintext highlighter-rouge">-c</code> will select a specific container for pods that have more than one</ul><h2 id="54-troubleshoot-application-failure"> <a href="#54-troubleshoot-application-failure" class="anchor-heading" aria-labelledby="54-troubleshoot-application-failure"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.4 Troubleshoot Application Failure</h2><ul><li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application/">Troubleshoot Applications</a><li>Status: Pending<ul><li>The Pod has been accepted by the Kubernetes cluster, but one or more of the containers has not been set up and made ready to run.<li>If no resources available on cluster, Cluster Autoscaling will increased node count if enabled<li>Once node count satisfied, pods in Pending status will be deployed</ul><li>Status: Waiting<ul><li>A container in the Waiting state is still running the operations it requires in order to complete start up</ul></ul><hr /><p>Describe the pod to get details on the configuration, containers, events, conditions, volumes, etc.</p><ul><li>Is the status equal to RUNNING?<li>Are there enough resources to schedule the pod?<li>Are there enough <code class="language-plaintext highlighter-rouge">hostPorts</code> remaining to schedule the pod?</ul><p><code class="language-plaintext highlighter-rouge">kubectl describe pod counter</code></p><div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">Name</span><span class="pi">:</span>         <span class="s">counter</span>
<span class="na">Namespace</span><span class="pi">:</span>    <span class="s">default</span>
<span class="na">Priority</span><span class="pi">:</span>     <span class="m">0</span>
<span class="na">Node</span><span class="pi">:</span>         <span class="s">gke-my-first-cluster-1-default-pool-504c1e77-xcvj/10.128.0.15</span>
<span class="na">Start Time</span><span class="pi">:</span>   <span class="s">Tue, 10 Nov 2020 16:33:10 -0600</span>
<span class="na">Labels</span><span class="pi">:</span>       <span class="s">&lt;none&gt;</span>
<span class="na">Annotations</span><span class="pi">:</span>  <span class="s">&lt;none&gt;</span>
<span class="na">Status</span><span class="pi">:</span>       <span class="s">Running</span>
<span class="na">IP</span><span class="pi">:</span>           <span class="s">10.104.1.7</span>
<span class="na">IPs</span><span class="pi">:</span>
  <span class="na">IP</span><span class="pi">:</span>  <span class="s">10.104.1.7</span>
<span class="na">Containers</span><span class="pi">:</span>
  <span class="na">count</span><span class="pi">:</span>
    <span class="na">Container ID</span><span class="pi">:</span>  <span class="s">docker://430313804a529153c1dc5badd1394164906a7dead8708a4b850a0466997e1c34</span>
    <span class="na">Image</span><span class="pi">:</span>         <span class="s">busybox</span>
    <span class="na">Image ID</span><span class="pi">:</span>      <span class="s">docker-pullable://busybox@sha256:a9286defaba7b3a519d585ba0e37d0b2cbee74ebfe590960b0b1d6a5e97d1e1d</span>
    <span class="na">Port</span><span class="pi">:</span>          <span class="s">&lt;none&gt;</span>
    <span class="na">Host Port</span><span class="pi">:</span>     <span class="s">&lt;none&gt;</span>
    <span class="na">Args</span><span class="pi">:</span>
      <span class="s">/bin/sh</span>
      <span class="s">-c</span>
      <span class="s">i=0; while </span><span class="kc">true</span><span class="s">; do</span>
        <span class="s">echo "$i</span><span class="err">:</span> <span class="s">$(date)" &gt;&gt; /var/log/1.log;</span>
        <span class="s">echo "$(date) INFO $i" &gt;&gt; /var/log/2.log;</span>
        <span class="s">i=$((i+1));</span>
        <span class="s">sleep 1;</span>
      <span class="s">done</span>

    <span class="na">State</span><span class="pi">:</span>          <span class="s">Running</span>
      <span class="s">Started</span><span class="err">:</span>      <span class="s">Tue, 10 Nov 2020 16:33:12 -0600</span>
    <span class="na">Ready</span><span class="pi">:</span>          <span class="s">True</span>
    <span class="na">Restart Count</span><span class="pi">:</span>  <span class="m">0</span>
    <span class="na">Environment</span><span class="pi">:</span>    <span class="s">&lt;none&gt;</span>
    <span class="na">Mounts</span><span class="pi">:</span>
      <span class="s">/var/log from varlog (rw)</span>
      <span class="s">/var/run/secrets/kubernetes.io/serviceaccount from default-token-2qnnp (ro)</span>
  <span class="na">count-log-1</span><span class="pi">:</span>
    <span class="na">Container ID</span><span class="pi">:</span>  <span class="s">docker://d5e95aa4aec3a55435d610298f94e7b8b2cfdf2fb88968f00ca4719a567a6e37</span>
    <span class="na">Image</span><span class="pi">:</span>         <span class="s">busybox</span>
    <span class="na">Image ID</span><span class="pi">:</span>      <span class="s">docker-pullable://busybox@sha256:a9286defaba7b3a519d585ba0e37d0b2cbee74ebfe590960b0b1d6a5e97d1e1d</span>
    <span class="na">Port</span><span class="pi">:</span>          <span class="s">&lt;none&gt;</span>
    <span class="na">Host Port</span><span class="pi">:</span>     <span class="s">&lt;none&gt;</span>
    <span class="na">Args</span><span class="pi">:</span>
      <span class="s">/bin/sh</span>
      <span class="s">-c</span>
      <span class="s">tail -n+1 -f /var/log/1.log</span>
    <span class="na">State</span><span class="pi">:</span>          <span class="s">Running</span>
      <span class="s">Started</span><span class="err">:</span>      <span class="s">Tue, 10 Nov 2020 16:33:13 -0600</span>
    <span class="na">Ready</span><span class="pi">:</span>          <span class="s">True</span>
    <span class="na">Restart Count</span><span class="pi">:</span>  <span class="m">0</span>
    <span class="na">Environment</span><span class="pi">:</span>    <span class="s">&lt;none&gt;</span>
    <span class="na">Mounts</span><span class="pi">:</span>
      <span class="s">/var/log from varlog (rw)</span>
      <span class="s">/var/run/secrets/kubernetes.io/serviceaccount from default-token-2qnnp (ro)</span>
  <span class="na">count-log-2</span><span class="pi">:</span>
    <span class="na">Container ID</span><span class="pi">:</span>  <span class="s">docker://eaa9983cbd55288a139b63c30cfe3811031dedfae0842b9233ac48db65387d4d</span>
    <span class="na">Image</span><span class="pi">:</span>         <span class="s">busybox</span>
    <span class="na">Image ID</span><span class="pi">:</span>      <span class="s">docker-pullable://busybox@sha256:a9286defaba7b3a519d585ba0e37d0b2cbee74ebfe590960b0b1d6a5e97d1e1d</span>
    <span class="na">Port</span><span class="pi">:</span>          <span class="s">&lt;none&gt;</span>
    <span class="na">Host Port</span><span class="pi">:</span>     <span class="s">&lt;none&gt;</span>
    <span class="na">Args</span><span class="pi">:</span>
      <span class="s">/bin/sh</span>
      <span class="s">-c</span>
      <span class="s">tail -n+1 -f /var/log/2.log</span>
    <span class="na">State</span><span class="pi">:</span>          <span class="s">Running</span>
      <span class="s">Started</span><span class="err">:</span>      <span class="s">Tue, 10 Nov 2020 16:33:13 -0600</span>
    <span class="na">Ready</span><span class="pi">:</span>          <span class="s">True</span>
    <span class="na">Restart Count</span><span class="pi">:</span>  <span class="m">0</span>
    <span class="na">Environment</span><span class="pi">:</span>    <span class="s">&lt;none&gt;</span>
    <span class="na">Mounts</span><span class="pi">:</span>
      <span class="s">/var/log from varlog (rw)</span>
      <span class="s">/var/run/secrets/kubernetes.io/serviceaccount from default-token-2qnnp (ro)</span>
<span class="na">Conditions</span><span class="pi">:</span>
  <span class="s">Type              Status</span>
  <span class="s">Initialized       True</span>
  <span class="s">Ready             True</span>
  <span class="s">ContainersReady   True</span>
  <span class="s">PodScheduled      True</span>
<span class="na">Volumes</span><span class="pi">:</span>
  <span class="na">varlog</span><span class="pi">:</span>
    <span class="na">Type</span><span class="pi">:</span>       <span class="s">EmptyDir (a temporary directory that shares a pod's lifetime)</span>
    <span class="na">Medium</span><span class="pi">:</span>
    <span class="na">SizeLimit</span><span class="pi">:</span>  <span class="s">&lt;unset&gt;</span>
  <span class="na">default-token-2qnnp</span><span class="pi">:</span>
    <span class="na">Type</span><span class="pi">:</span>        <span class="s">Secret (a volume populated by a Secret)</span>
    <span class="na">SecretName</span><span class="pi">:</span>  <span class="s">default-token-2qnnp</span>
    <span class="na">Optional</span><span class="pi">:</span>    <span class="kc">false</span>
<span class="na">QoS Class</span><span class="pi">:</span>       <span class="s">BestEffort</span>
<span class="na">Node-Selectors</span><span class="pi">:</span>  <span class="s">&lt;none&gt;</span>
<span class="na">Tolerations</span><span class="pi">:</span>     <span class="s">node.kubernetes.io/not-ready:NoExecute op=Exists for 300s</span>
                 <span class="s">node.kubernetes.io/unreachable:NoExecute op=Exists for 300s</span>
<span class="na">Events</span><span class="pi">:</span>
  <span class="s">Type    Reason     Age   From                                                        Message</span>
  <span class="s">----    ------     ----  ----                                                        -------</span>
  <span class="s">Normal  Scheduled  30m   default-scheduler                                           Successfully assigned default/counter to gke-my-first-cluster-1-default-pool-504c1e77-xcvj</span>
  <span class="s">Normal  Pulling    30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Pulling image "busybox"</span>
  <span class="s">Normal  Pulled     30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Successfully pulled image "busybox"</span>
  <span class="s">Normal  Created    30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Created container count</span>
  <span class="s">Normal  Started    30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Started container count</span>
  <span class="s">Normal  Pulling    30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Pulling image "busybox"</span>
  <span class="s">Normal  Created    30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Created container count-log-1</span>
  <span class="s">Normal  Pulled     30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Successfully pulled image "busybox"</span>
  <span class="s">Normal  Started    30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Started container count-log-1</span>
  <span class="s">Normal  Pulling    30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Pulling image "busybox"</span>
  <span class="s">Normal  Pulled     30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Successfully pulled image "busybox"</span>
  <span class="s">Normal  Created    30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Created container count-log-2</span>
  <span class="s">Normal  Started    30m   kubelet, gke-my-first-cluster-1-default-pool-504c1e77-xcvj  Started container count-log-2</span>
</code></pre></div></div><hr /><p>Validate the commands being presented to the pod to ensure nothing was configured incorrectly.</p><p><code class="language-plaintext highlighter-rouge">kubectl apply --validate -f mypod.yaml</code></p><h2 id="55-troubleshoot-cluster-component-failure"> <a href="#55-troubleshoot-cluster-component-failure" class="anchor-heading" aria-labelledby="55-troubleshoot-cluster-component-failure"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.5 Troubleshoot Cluster Component Failure</h2><ul><li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/">Troubleshoot Clusters</a><li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/#a-general-overview-of-cluster-failure-modes">A general overview of cluster failure modes</a><li><a href="https://kubernetes.io/docs/concepts/overview/components/#control-plane-components">Control Plane Components</a><li><a href="https://kubernetes.io/docs/concepts/overview/components/#node-components">Node Components</a></ul><hr /><p>Components to investigate:</p><ul><li>Control Plane Components<ul><li><code class="language-plaintext highlighter-rouge">kube-apiserver</code><li><code class="language-plaintext highlighter-rouge">etcd</code><li><code class="language-plaintext highlighter-rouge">kube-scheduler</code><li><code class="language-plaintext highlighter-rouge">kube-controller-manager</code><li><code class="language-plaintext highlighter-rouge">cloud-controller-manager</code></ul><li>Node Components<ul><li><code class="language-plaintext highlighter-rouge">kubelet</code><li><code class="language-plaintext highlighter-rouge">kube-proxy</code><li>Container runtime (e.g. Docker)</ul></ul><hr /><p>View the components with:</p><p><code class="language-plaintext highlighter-rouge">kubectl get all -n kube-system</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                                               READY   STATUS    RESTARTS   AGE
pod/konnectivity-agent-56nck                                       1/1     Running   0          15d
pod/konnectivity-agent-gmklx                                       1/1     Running   0          15d
pod/konnectivity-agent-wg92c                                       1/1     Running   0          15d
pod/kube-dns-576766df6b-cz4ln                                      3/3     Running   0          15d
pod/kube-dns-576766df6b-rcsk7                                      3/3     Running   0          15d
pod/kube-dns-autoscaler-7f89fb6b79-pq66d                           1/1     Running   0          15d
pod/kube-proxy-gke-my-first-cluster-1-default-pool-504c1e77-m9lk   1/1     Running   0          15d
pod/kube-proxy-gke-my-first-cluster-1-default-pool-504c1e77-xcvj   1/1     Running   0          15d
pod/kube-proxy-gke-my-first-cluster-1-default-pool-504c1e77-zg6v   1/1     Running   0          15d
pod/l7-default-backend-7fd66b8b88-ng57f                            1/1     Running   0          15d
pod/metrics-server-v0.3.6-7c5cb99b6f-2d8bx                         2/2     Running   0          15d

NAME                           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>         AGE
service/default-http-backend   NodePort    10.108.1.184   &lt;none&gt;        80:32084/TCP    15d
service/kube-dns               ClusterIP   10.108.0.10    &lt;none&gt;        53/UDP,53/TCP   15d
service/metrics-server         ClusterIP   10.108.1.154   &lt;none&gt;        443/TCP         15d

NAME                                      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                                                        AGE
daemonset.apps/konnectivity-agent         3         3         3       3            3           &lt;none&gt;                                                               15d
daemonset.apps/kube-proxy                 0         0         0       0            0           kubernetes.io/os<span class="o">=</span>linux,node.kubernetes.io/kube-proxy-ds-ready<span class="o">=</span><span class="nb">true   </span>15d
daemonset.apps/metadata-proxy-v0.1        0         0         0       0            0           cloud.google.com/metadata-proxy-ready<span class="o">=</span><span class="nb">true</span>,kubernetes.io/os<span class="o">=</span>linux    15d
daemonset.apps/nvidia-gpu-device-plugin   0         0         0       0            0           &lt;none&gt;                                                               15d

NAME                                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/kube-dns                2/2     2            2           15d
deployment.apps/kube-dns-autoscaler     1/1     1            1           15d
deployment.apps/l7-default-backend      1/1     1            1           15d
deployment.apps/metrics-server-v0.3.6   1/1     1            1           15d

NAME                                               DESIRED   CURRENT   READY   AGE
replicaset.apps/kube-dns-576766df6b                2         2         2       15d
replicaset.apps/kube-dns-autoscaler-7f89fb6b79     1         1         1       15d
replicaset.apps/l7-default-backend-7fd66b8b88      1         1         1       15d
replicaset.apps/metrics-server-v0.3.6-7c5cb99b6f   1         1         1       15d
replicaset.apps/metrics-server-v0.3.6-7ff8cdbc49   0         0         0       15d
</code></pre></div></div><hr /><p>Retrieve detailed information about the cluster</p><p><code class="language-plaintext highlighter-rouge">kubectl cluster-info</code> or <code class="language-plaintext highlighter-rouge">kubectl cluster-info dump</code></p><hr /><p>Retrieve a list of known API resources to aid with describing or troubleshooting</p><p><code class="language-plaintext highlighter-rouge">kubectl api-resources</code></p><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                              SHORTNAMES   APIGROUP                       NAMESPACED   KIND
bindings                                                                      <span class="nb">true         </span>Binding
componentstatuses                 cs                                          <span class="nb">false        </span>ComponentStatus
configmaps                        cm                                          <span class="nb">true         </span>ConfigMap
endpoints                         ep                                          <span class="nb">true         </span>Endpoints
events                            ev                                          <span class="nb">true         </span>Event
limitranges                       limits                                      <span class="nb">true         </span>LimitRange
namespaces                        ns                                          <span class="nb">false        </span>Namespace
nodes                             no                                          <span class="nb">false        </span>Node
persistentvolumeclaims            pvc                                         <span class="nb">true         </span>PersistentVolumeClaim
persistentvolumes                 pv                                          <span class="nb">false        </span>PersistentVolume

&lt;snip&gt;
</code></pre></div></div><hr /><p><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/#looking-at-logs">Check the logs</a> in <code class="language-plaintext highlighter-rouge">/var/log</code> on the master and worker nodes:</p><ul><li>Master<ul><li><code class="language-plaintext highlighter-rouge">/var/log/kube-apiserver.log</code> - API Server, responsible for serving the API<li><code class="language-plaintext highlighter-rouge">/var/log/kube-scheduler.log</code> - Scheduler, responsible for making scheduling decisions<li><code class="language-plaintext highlighter-rouge">/var/log/kube-controller-manager.log</code> - Controller that manages replication controllers</ul><li>Worker Nodes<ul><li><code class="language-plaintext highlighter-rouge">/var/log/kubelet.log</code> - Kubelet, responsible for running containers on the node<li><code class="language-plaintext highlighter-rouge">/var/log/kube-proxy.log</code> - Kube Proxy, responsible for service load balancing</ul></ul><h2 id="56-troubleshoot-networking"> <a href="#56-troubleshoot-networking" class="anchor-heading" aria-labelledby="56-troubleshoot-networking"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 5.6 Troubleshoot Networking</h2><ul><li><a href="https://github.com/coreos/flannel/blob/master/Documentation/troubleshooting.md#kubernetes-specific">Flannel Troubleshooting</a><ul><li>The flannel kube subnet manager relies on the fact that each node already has a podCIDR defined.</ul><li><a href="https://docs.projectcalico.org/maintenance/troubleshoot/">Calico Troubleshooting</a><ul><li><a href="https://docs.projectcalico.org/maintenance/troubleshoot/troubleshooting#containers-do-not-have-network-connectivity">Containers do not have network connectivity</a></ul></ul><hr><h2 class="text-delta">Table of contents</h2><ul><li> <a href="/my-tech/doc/Kubernetes/doc-1/">Kubernetes 1.24 Installation</a><li> <a href="/my-tech/doc/Kubernetes/doc-2/">CKA Preparation, 1.22</a></ul></main><hr><footer><p><a href="#top" id="back-to-top">Back to top</a></p><span>[ <a href="https://github.com/kyoon55">Github</a> ]</span> <span>[ <a href="mailto:kyoon5@gwu.edu">Click here to email me</a> ]</span><div class="d-flex mt-2"></div></footer></div></div><div class="search-overlay"></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@9.1.6/dist/mermaid.min.js"></script> <script> var config = {} ; mermaid.initialize(config); window.mermaid.init(undefined, document.querySelectorAll('.language-mermaid')); </script><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="stylesheet" href="/my-tech/assets/css/just-the-docs-default.css"> <script src="/my-tech/assets/js/vendor/lunr.min.js"></script> <script src="/my-tech/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/my-tech/assets/images/favicon.ico" type="image/x-icon"><title>Kubernetes | My SRE Stuff</title><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Kubernetes" /><meta property="og:locale" content="en_US" /><meta name="description" content="This page is full of articles for my SRE knowledge" /><meta property="og:description" content="This page is full of articles for my SRE knowledge" /><link rel="canonical" href="http://localhost:4000/my-tech/docs/Kubernetes" /><meta property="og:url" content="http://localhost:4000/my-tech/docs/Kubernetes" /><meta property="og:site_name" content="My SRE Stuff" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-02-04T00:00:00-05:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Kubernetes" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-02-04T00:00:00-05:00","datePublished":"2023-02-04T00:00:00-05:00","description":"This page is full of articles for my SRE knowledge","headline":"Kubernetes","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/my-tech/docs/Kubernetes"},"url":"http://localhost:4000/my-tech/docs/Kubernetes"}</script>
